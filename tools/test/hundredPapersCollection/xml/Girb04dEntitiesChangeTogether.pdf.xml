<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<page confidence="0.847205">
1
</page>
<title confidence="0.896424">
Identifying Entities That Change Together
</title>
<author confidence="0.91385">
Tudor Gı̂rba1, Stéphane Ducasse2, Radu Marinescu3 and Daniel Raţiu4
</author>
<affiliation confidence="0.9295025">
1,2 Software Composition Group
University of Berne, Switzerland
</affiliation>
<email confidence="0.95725">
{girba, ducasse}@iam.unibe.ch
</email>
<sectionHeader confidence="0.594383" genericHeader="method">
3,4 LOOSE Research Group
</sectionHeader>
<affiliation confidence="0.990827">
University of Timişoara, Romania
</affiliation>
<email confidence="0.969275">
{radum, ratiud}@cs.utt.ro
</email>
<sectionHeader confidence="0.8287205" genericHeader="method">
Abstract
1 Software system need to change over time to cope
</sectionHeader>
<bodyText confidence="0.989321125">
with the new requirements. Furthermore, due to design
decisions, the new requirements happen to crosscut the
system’s structure. Understanding how changes appear
in the system can reveal hidden dependencies between
different parts of the system. We propose to group entities
that change together according to a logical expression that
specifies the change condition. Furthermore, we can group
entities at different levels of abstraction (i.e., method, class,
package). Our approach is based on an explicit history
meta model that centers around the notion of history and
which enables the definition of historical measurements
which summarize the changes. We apply our approach
on two large case studies and show how we can identify
groups of related entities and detect bad smells.
I. Introduction
Software systems need to change over time to cope
with the new requirements [1]. As the requirements happen
to crosscut the system’s structure, changes will have to
be made in multiple places. Understanding how changes
appear in the system is important for detecting hidden
dependencies between its parts.
In the recent period work has been carried out to
detect and interpret groups of software entities that change
together [2] [3] [4]. Yet, the detection is based on change
</bodyText>
<sectionHeader confidence="0.6804115" genericHeader="method">
1Ninth IEEE Workshop on Empirical Studies of Software Maintenance
(WESS 2004)
</sectionHeader>
<bodyText confidence="0.999386363636363">
information concerning one property, and is mostly based
on file level information.
We propose an approach which detects evolutionary
groups based on more than one property. We first define
a history meta model and based on this meta model
we define historical measurements which summarize the
evolution of entities. We use these measurements to detect
changes between two versions, and build an Evolution
Matrix [5] annotated with changes. We use the matrix as
an incidence table for the input into a concept analysis
machine which returns the groups of entities that changed
certain properties in the same versions. Also, for building
the matrix of changes, we make use of logical expressions
which combine properties with thresholds and which run
on two versions of the system to detect interesting entities.
Example. ShotgunSurgery appears when whenever we
have to change a class we have to change a number of
other classes[6]. We would suspect a group of classes of
such a bad smell, when they repeatedly keep their external
behavior constant and change the implementation. We can
detect this kind of change in a class in the versions in
which the number of methods did not change, while the
number of statements changed.
We can apply our approach on any kind of entities
we have in the meta model. In this paper we show
how we detect groups of packages, classes and methods.
We applied our approach on two large open source case
studies.
Next, we briefly introduce the notion of history as a
first-class entity and define two generic historical measure-
ments. We introduce our approach for grouping histories
using historical measurements and concept analysis, and
then show how we apply it on different levels of abstrac-
</bodyText>
<page confidence="0.980956">
2
</page>
<bodyText confidence="0.997355">
tions (i.e., method, class, package). We discuss the results
we obtained when applying our approach on two large
case open source studies, and in the end, we conclude and
present the future work.
II. History and History Measurements
We define a history to be a sequence of versions of
the same kind of entity (e.g., class history, system history,
etc.). By a version we understand a snapshot of an entity at
a certain point in time (e.g., class version, system version,
etc.).
Example. In the left side of Figure 1 we use a
simplified example of the Evolution Matrix [5] to display
a system history with 6 versions. A cell in the matrix
is marked by a square and represents a class version. A
line in the matrix represents a class history and a column
represents a system version. In the figure, class A was
present in all the version of the system, class B was
removed in the last system version while class E appeared
in the system only the third system version.
Addition of a Version Property (A). We define a
generic measurement, called addition of a version property
P (A(P, i)), as the addition of that property between version
i− 1 and i of the history H:
</bodyText>
<equation confidence="0.9991702">
(i &gt; 1)
Ai(P, H) =
{
Pi(H)− Pi−1(H), Pi(H)− Pi−1(H) &gt; 0
0, Pi(H)− Pi−1(H) 6 0 (1)
</equation>
<bodyText confidence="0.9590445">
Evolution of a Version Property (E). We define a
generic measurement, called evolution of a version prop-
erty P (Ei(P )), as being the absolute difference of that
property between version i− 1 and i:
</bodyText>
<equation confidence="0.945028">
(i &gt; 1) Ei(P, H) = |Pi(H)− Pi−1(H) |(2)
</equation>
<bodyText confidence="0.922">
We instantiate the above mentioned measurements by
applying them on different version properties of different
types of entities:
</bodyText>
<listItem confidence="0.961189833333333">
• Method: NOS (number of statements), CYCLO (MC-
Cabe cyclomatic number [7]).
• Class: NOM (number of methods), WNOC (number
of all subclasses).
• Package: NOCls (number of classes), NOM (number
of methods).
</listItem>
<bodyText confidence="0.996563179487179">
The E measurement shows a change of a certain
property, while the A measurement shows the additions
of a certain version property. Thus, these measurements
summarize the evolution of properties.
III. Grouping Mechanism
In the left side of Figure 1 we display an Evolution
Matrix in which each square represents a class version
and the number inside a square represents the number of
methods in that particular class version. A grayed square
shows a change in the number of methods of a class version
as compared with the previous version (Ei(NOM) &gt; 0).
Based on such a matrix we can build a concept lattice
by considering the histories as entities and the properties
are given by ”grayed in version x”. In the right side of
Figure 1, we show the concept lattice obtained from the
Evolution Matrix on the left.
Each concept in the lattice represents all the class
histories which changed certain properties together in those
particular versions. In the given example, class history A
and D changed their number of methods in version 2 and
version 6.
We not only want to detect entities that change one
certain property in the same time, we want to detect entities
that change more properties, and/or do not change other
properties. For example, to detect parallel inheritances it is
enough to just look at the number of children of classes;
but, when we want to look for classes which need to
change the internals of the methods in the same time
without adding any new functionality, we need to look
for classes which change their size, but not the number of
methods.
We encode this information in a expressions which
consist of logical combination of historical measurements.
These expressions are applied at every version on the last
two versions. In the example from Figure 1, the expression
used was Ei(NOM) &gt; 0 which we applied on class
histories.
In the followings we will introduce several expressions
applicable on packages, classes and respectively methods.
</bodyText>
<listItem confidence="0.640975142857143">
A. Method Histories Grouping Expressions.
Parallel Complexity. A set of methods are effected by
Parallel Complexity when a change in the complexity in
one method involves changes in the complexity of other
methods. As a measure of complexity we used the McCabe
cyclomatic number. Classes with parallel complexity could
reveal parallel conditionals.
</listItem>
<equation confidence="0.984108">
ParallelComplexity : (Ai(CY CLO) &gt; 0) (3)
</equation>
<bodyText confidence="0.98880775">
Parallel Bugs. We name a change a bug fix, when no
complexity is added to the method, but the implementation
changes. When we detect repetitive such bug fixes in more
methods in the same versions, we group those methods in a
</bodyText>
<page confidence="0.978526">
3
</page>
<figureCaption confidence="0.891124333333333">
Fig. 1. Example of applying concept analysis to group class histories based on the changes in number
of methods. The Evolution Matrix on the left is the incident table used as the input for the concept
analysis machine which outputs the concept lattice on the right.
</figureCaption>
<bodyText confidence="0.88883">
Parallel Bugs group. Such a group, might give indications
of similar implementation which could be factor out. As an
implementation measure we used number of statements.
</bodyText>
<equation confidence="0.557955">
ParallelBugs : (Ei(NOS) &gt; 0) ∧ Ei(CY CLO) = 0) (4)
</equation>
<listItem confidence="0.292900142857143">
B. Class Histories Grouping Expressions
Shotgun Surgery. The Shotgun Surgery bad-smell is
encountered every time when a change operated in a class
involves a lot of small changes to a lot of different classes
[6]. We detect this bad smell, by looking at the classes
which do not change their interface, but change their
implementation together.
</listItem>
<equation confidence="0.992873">
ShotgunSurgery = (Ei(NOM) = 0 ∧ Ei(NOS) &gt; 0) (5)
</equation>
<bodyText confidence="0.959300857142857">
Parallel Inheritance. Parallel Inheritance is detected in
the classes which change their number of children together
[6]. Such a characteristic is not necessary a bad smell, but
gives indications of a hidden link between two hierarchies.
For example, if we detect a main hierarchy and a test
hierarchy as being parallel, gives us indication that the
tests were developed in parallel with the code.
</bodyText>
<equation confidence="0.986872">
ParallelInheritance = (Ai(WNOC) &gt; 0) (6)
</equation>
<bodyText confidence="0.90449375">
Parralel Semantics. Methods specify the semantics of
a class. With Parallel Semantics we detect classes which
add methods in parallel. Such a characteristic could reveal
hidden dependencies between classes.
</bodyText>
<equation confidence="0.863644">
ParallelSemantics = (Ai(NOM) &gt; 0) (7)
</equation>
<listItem confidence="0.4351395">
C. Package Histories Grouping Expression
Package Parallel Semantics. If a group of classes is
</listItem>
<bodyText confidence="0.9558215">
detected, as having parallel semantics, we would want to
relate the containing packages as well. Package Parallel
Semantics detects packages where some methods have
been added, but no class have been added or removed.
</bodyText>
<equation confidence="0.99982">
PackageParallelSemantics = (Ei(NOCls) = 0) ∧
(Ai(NOM) &gt; 0) (8)
</equation>
<page confidence="0.875489">
4
</page>
<bodyText confidence="0.939315888888889">
IV. Experiments: JBoss
For our experiments we chose 41 versions of JBoss2.
JBoss is an open source J2EE application server written
in Java. The versions we selected for the experiments are
at two weeks distance from one another starting from the
beginning of 2001 until the end of 2002. Table I shows
the characteristics of the case study. The first version has
632 classes, the last one has 4276 classes (we took into
consideration all test classes, interfaces and inner classes).
</bodyText>
<table confidence="0.453820666666667">
System Language Versions First Version
(Size)
Last Version
(Size)
JBoss Java 41 40 kLOC 281 kLOC
632 classes 4276 classes
</table>
<tableCaption confidence="0.320012">
TABLE I. Characteristics of the JBoss case
</tableCaption>
<bodyText confidence="0.98682216">
study.
Due to space limitation, we will only discuss the
ParallelInheritance results we obtained on JBoss.
After applying the mechanism described above, we ob-
tained 68 groups of class histories which added subclasses
in the same time. Manual inspection showed there were
a lot of repetitions (due to the way the concept lattice is
built), and just a limited number of groups were useful.
Furthermore, inside a group not all classes were relevant
for that particular group.
For example, in 19 versions a class was added in
the JBossTestCase hierarchy (JBossTestCase is
the root of the JBoss test cases). Another example is
ServiceMBeanSupport which is the root of the largest
hierarchy of JBoss. In this hierarchy, classes were added
in 18 versions. That means that both JBossTestCase
and ServiceMBeanSupport were present in a large
number of groups, but was not necessary related to the
other classes in these groups.
These results showed that just applying concept analysis
produced too many false positives. That is why we added a
filtering step. The filtering step consists in identifying and
removing from the groups the entities that changed their
relevant properties (i.e., according to the expression) more
times than the number of properties detected in a group:
</bodyText>
<equation confidence="0.99323825">
FilteringRule =
groupV ersions
totalChangedV ersions
&gt; threshold (9)
</equation>
<bodyText confidence="0.984209333333333">
In our experiments, we chose the threshold to be 3/4.
For example, if JBossTestCase was part of a group
of classes which changed their number of subclasses in
</bodyText>
<footnote confidence="0.8539834">
10 versions, we would rule the class out of the group. We
chose an aggressive threshold to reduce the number of false
2See http://www.jboss.org for more information.
positives as much as possible, in the detriment of having
true negatives.
</footnote>
<figure confidence="0.70582">
Class Histories Versions
org::jboss::system::ServiceMBeanSupport
org::jboss::test::JBossTestCase
24 27 28
29 30 32
33 34 37
38 39 40
41 19 20
javax::ejb::EJBLocalHome
javax::ejb::EJBLocalObject
24 41 28
30 32 36
37 38 23
TABLE II. Parallel Inheritance in JBoss
</figure>
<bodyText confidence="0.94921875">
After the filtering step, we obtained just two groups. In
Table II we show the class histories and the versions in
which they changed the number of children.
In the first group we have two classes which
change their number of children 15 times:
ServiceMBeanSupport and JBossTestCase.
The interpretation of this group is that the largest
hierarchy in JBoss is highly tested.
The second group detects a relationship
between the EJB interfaces: EJBLocalHome and
EJBLocalObject. This is due to the architecture of
EJB which requires that a bean has to have a Home and
an Object component.
V. Implementation: Moose, Van and ConAn
We carried the experiments using a combination of
tools:
</bodyText>
<figure confidence="0.4672876">
• Van is our version analysis tool. It implements the
history meta model (Hismo) and is built on top of
Moose[8].
• ConAn is a concept analysis developed on top of
Moose.
</figure>
<sectionHeader confidence="0.630898" genericHeader="method">
VI. Related Work
</sectionHeader>
<bodyText confidence="0.999543615384615">
The first work to study the entities that change together
was performed by Gall et al. [2]. The authors use the
change information to define a proximity measurements
which they use to cluster related entities. The work has
been followed up by the same authors [9] and by Itko et
al. [3].
Shirabad et al. employ machine learning techniques to
detect files which are likely to need to be changed when
a particular file is changed [10].
As opposite with the previous approaches, Zimmerman
et al. placed their analysis at the level of entities in the
meta model [4]. Their focus was to provide a mechanism
to warn developers that: “Programmers who changed these
</bodyText>
<page confidence="0.965747">
5
</page>
<bodyText confidence="0.998651678571428">
functions also changed. . . ”. Their approach differs from
ours because they only look at syntactic changes, while we
identify changes based on the semantics of the changes.
Furthermore, our approach takes into consideration differ-
ent changes in the same time.
Davey and Burd proposed the usage of concept analysis
to detect evolutionary concepts, but there was no imple-
mentation evidence [11].
Detection of problems in the source code structure has
long been a main issue in the quality assurance community.
Marinescu [12] detects design flaws by defining detection
strategies. Ciupke employed queries usually implemented
in Prolog to detect “critical design fragments” [13]. Tourwe
et al. also explored the use of logic programming to detect
design flaws [14]. vanEmden and Moonen detected bad
smells by looking at code patterns [15]. These approaches
differs from ours because they use only the last version of
the code, while we take into account historical information.
Furthermore, vanEmden and Moonen proposed as future
research the usage of historical information to detect
Shotgun Surgery or Parallel Inheritance.
We developed a previous approach to using the history
of entities to detect design flaws, but in that case we
extended the concept of detection strategies proposed by
Marinescu to take into account the time information and
showed how we improved the detection [16] [17].
Two of the authors already used historical information
to characterize how changes appear during the history of
systems[18].
VII. Conclusions and Future Work
Understanding how a system changes can reveal hid-
den dependencies between different parts of the system.
Moreover, such dependencies might reveal bad smells in
the design.
We proposed the usage of historical information to
detect parts of the system that change in the same time,
according to different rules. For that, we defined a history
meta model and history measurements. Based on this
model we built queries which detect different types of
changes. By applying these queries on every version we
obtained an Evolution Matrix annotated with the change
information which we then used as input for a concept
analysis machine. The result obtained by the machine were
groups of entities that change together and the versions in
which they changed. We applied our approach on one large
open source case study and discussed some of the results
we obtained.
According to our algorithm the effectiveness of the
approach is highly affected by the value of the threshold.
When the threshold is high (i.e., close to 1) we want
to remove the false positives but we risk missing true
negatives. Further work is required to better understand
the nature of this threshold and its interpretation.
In the future we would also like to apply our approach
on more case studies and analyze in depth the results we
obtain at different levels of abstractions.
</bodyText>
<sectionHeader confidence="0.969889" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.814686666666667">
Ducasse and Gı̂rba gratefully acknowledge the financial
support of the Swiss National Science Foundation for
the projects “Tools and Techniques for Decomposing and
</bodyText>
<reference confidence="0.88026475">
Composing Software” (SNF Project No. 2000-067855.02,
Oct. 2002 - Sept. 2004) and “RECAST: Evolution of
Object-Oriented Applications” (SNF Project No. 620-
066077, Sept. 2002 - Aug. 2006).
</reference>
<bodyText confidence="0.672576">
Gı̂rba would like to thank European Science Foundation
for the financial support.
</bodyText>
<sectionHeader confidence="0.891794" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999145022727273">
[1] M. M. Lehman and L. Belady, Program Evolution — Processes of
Software Change. London Academic Press, 1985.
[2] H. Gall, K. Hajek, and M. Jazayeri, “Detection of logical coupling
based on product release history,” in Proceedings of the Interna-
tional Conference on Software Maintenance 1998 (ICSM ’98), 1998,
pp. 190–198.
[3] J. Itkonen, M. Hillebrand, and V. Lappalainen, “Application of
relation analysis to a small java software,” in Proceedings of the
Conference on Software Maintenance and Reengineering (CSMR
2004), 2004, pp. 233–239.
[4] T. Zimmermann, P. Weißgerber, S. Diehl, and A. Zeller, “Mining
version histories to guide software changes,” in 26th International
Conference on Software Engineering (ICSE 2004), 2004.
[5] M. Lanza and S. Ducasse, “Understanding software evolution using
a combination of software visualization and software metrics,” in
Proceedings of LMO 2002 (Langages et Modèles à Objets, 2002,
pp. 135–149.
[6] M. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts, Refac-
toring: Improving the Design of Existing Code. Addison Wesley,
1999.
[7] T. McCabe, “A measure of complexity,” IEEE Transactions on
Software Engineering, vol. 2, no. 4, pp. 308–320, Dec. 1976.
[8] S. Ducasse, M. Lanza, and S. Tichelaar, “Moose: an extensi-
ble language-independent environment for reengineering object-
oriented systems,” in Proceedings of the Second International
Symposium on Constructing Software Engineering Tools (CoSET
2000), June 2000.
[9] H. Gall, M. Jazayeri, and J. Krajewski, “Cvs release history data
for detecting logical couplings,” in International Workshop on
Principles of Software Evolution (IWPSE 2003), 2003, pp. 13–23.
[10] J. S. Shirabad, T. C. Lethbridge, and S. Matwin, “Mining the
maintenance history of a legacy software system,” in International
Conference on Software Maintenance (ICSM 2003), 2003, pp. 95–
104.
[11] J. Davey and E. Burd, “Clustering and concept analysis for software
evolution,” in Proceedings of the 4th international Workshop on
Principles of Software Evolution (IWPSE 2001), Vienna, Austria,
2001, pp. 146–149.
[12] R. Marinescu, “Measurement and quality in object-oriented design,”
Ph.D. Thesis, Department of Computer Science, ”Politehnica” Uni-
versity of Timişoara, 2002.
[13] O. Ciupke, “Automatic detection of design problems in object-
oriented reengineering,” in Proceedings of TOOLS 30 (USA), 1999,
pp. 18–32.
</reference>
<page confidence="0.893569">
6
</page>
<reference confidence="0.999356588235294">
[14] K. Mens, T. Mens, and M. Wermelinger, “Maintaining software
through intentional source-code views,” in Proceedings of SEKE
2002. ACM Press, 2002, pp. 289–296.
[15] E. van Emden and L. Moonen, “Java quality assurance by detecting
code smells,” in Proc. 9th Working Conf. Reverse Engineering.
IEEE Computer Society Press, Oct. 2002, pp. 97–107.
[16] D. Ratiu, “Time-based detection strategies,” Master’s thesis, Faculty
of Automatics and Computer Science, ”Politehnica” University of
Timişoara, Sept. 2003.
[17] D. Ratiu, S. Ducasse, T. Gı̂rba, and R. Marinescu, “Using history
information to improve design flaws detection,” in Proceedings
of the Conference on Software Maintenance and Reengineering
(CSMR 2004), 2004, pp. 233–232.
[18] T. Gı̂rba, S. Ducasse, and M. Lanza, “Yesterday’s weather: Guiding
early reverse engineering efforts by summarizing the evolution of
changes,” in 20th International Conference on Software Mainte-
nance (ICSM 2004), 2004.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.337300">
<note confidence="0.779004">1</note>
<title confidence="0.995969">Identifying Entities That Change Together</title>
<author confidence="0.982825">Tudor Gı̂rba</author>
<author confidence="0.982825">Stéphane Ducasse</author>
<author confidence="0.982825">Radu Marinescu</author>
<author confidence="0.982825">Daniel Raţiu</author>
<affiliation confidence="0.87091">1,2 Software Composition Group University of Berne, Switzerland</affiliation>
<email confidence="0.833544">girba@iam.unibe.ch</email>
<email confidence="0.833544">ducasse@iam.unibe.ch</email>
<affiliation confidence="0.873203">3,4 LOOSE Research Group University of Timişoara, Romania</affiliation>
<email confidence="0.97879">radum@cs.utt.ro</email>
<email confidence="0.97879">ratiud@cs.utt.ro</email>
<abstract confidence="0.998819375">1 Software system need to change over time to cope with the new requirements. Furthermore, due to design decisions, the new requirements happen to crosscut the system’s structure. Understanding how changes appear in the system can reveal hidden dependencies between different parts of the system. We propose to group entities that change together according to a logical expression that specifies the change condition. Furthermore, we can group entities at different levels of abstraction (i.e., method, class, package). Our approach is based on an explicit history meta model that centers around the notion of history and which enables the definition of historical measurements which summarize the changes. We apply our approach on two large case studies and show how we can identify groups of related entities and detect bad smells.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Composing Software”</author>
</authors>
<title>and “RECAST: Evolution of Object-Oriented Applications”</title>
<date>2000</date>
<tech>SNF Project No. 620-066077,</tech>
<marker>Software”, 2000</marker>
<rawString> Composing Software” (SNF Project No. 2000-067855.02, Oct. 2002 - Sept. 2004) and “RECAST: Evolution of Object-Oriented Applications” (SNF Project No. 620-066077, Sept. 2002 - Aug. 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M M Lehman</author>
<author>L Belady</author>
</authors>
<date>1985</date>
<booktitle>Program Evolution — Processes of Software Change.</booktitle>
<publisher>London Academic Press,</publisher>
<contexts>
<context position="1231" citStr="[1]" startWordPosition="180" endWordPosition="180">that change together according to a logical expression that specifies the change condition. Furthermore, we can group entities at different levels of abstraction (i.e., method, class, package). Our approach is based on an explicit history meta model that centers around the notion of history and which enables the definition of historical measurements which summarize the changes. We apply our approach on two large case studies and show how we can identify groups of related entities and detect bad smells. I. Introduction Software systems need to change over time to cope with the new requirements [1]. As the requirements happen to crosscut the system’s structure, changes will have to be made in multiple places. Understanding how changes appear in the system is important for detecting hidden dependencies between its parts. In the recent period work has been carried out to detect and interpret groups of software entities that change together [2] [3] [4]. Yet, the detection is based on change 1Ninth IEEE Workshop on Empirical Studies of Software Maintenance (WESS 2004) information concerning one property, and is mostly based on file level information. We propose an approach which detects evo</context>
</contexts>
<marker>[1]</marker>
<rawString>M. M. Lehman and L. Belady, Program Evolution — Processes of Software Change. London Academic Press, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Gall</author>
<author>K Hajek</author>
<author>M Jazayeri</author>
</authors>
<title>Detection of logical coupling based on product release history,”</title>
<date>1998</date>
<journal>ICSM</journal>
<booktitle>in Proceedings of the International Conference on Software Maintenance</booktitle>
<volume>98</volume>
<pages>190--198</pages>
<contexts>
<context position="1581" citStr="[2]" startWordPosition="235" endWordPosition="235">s which summarize the changes. We apply our approach on two large case studies and show how we can identify groups of related entities and detect bad smells. I. Introduction Software systems need to change over time to cope with the new requirements [1]. As the requirements happen to crosscut the system’s structure, changes will have to be made in multiple places. Understanding how changes appear in the system is important for detecting hidden dependencies between its parts. In the recent period work has been carried out to detect and interpret groups of software entities that change together [2] [3] [4]. Yet, the detection is based on change 1Ninth IEEE Workshop on Empirical Studies of Software Maintenance (WESS 2004) information concerning one property, and is mostly based on file level information. We propose an approach which detects evolutionary groups based on more than one property. We first define a history meta model and based on this meta model we define historical measurements which summarize the evolution of entities. We use these measurements to detect changes between two versions, and build an Evolution Matrix [5] annotated with changes. We use the matrix as an incidence</context>
<context position="13388" citStr="[2]" startWordPosition="2201" endWordPosition="2201">s highly tested. The second group detects a relationship between the EJB interfaces: EJBLocalHome and EJBLocalObject. This is due to the architecture of EJB which requires that a bean has to have a Home and an Object component. V. Implementation: Moose, Van and ConAn We carried the experiments using a combination of tools: • Van is our version analysis tool. It implements the history meta model (Hismo) and is built on top of Moose[8]. • ConAn is a concept analysis developed on top of Moose. VI. Related Work The first work to study the entities that change together was performed by Gall et al. [2]. The authors use the change information to define a proximity measurements which they use to cluster related entities. The work has been followed up by the same authors [9] and by Itko et al. [3]. Shirabad et al. employ machine learning techniques to detect files which are likely to need to be changed when a particular file is changed [10]. As opposite with the previous approaches, Zimmerman et al. placed their analysis at the level of entities in the meta model [4]. Their focus was to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”.</context>
</contexts>
<marker>[2]</marker>
<rawString>H. Gall, K. Hajek, and M. Jazayeri, “Detection of logical coupling based on product release history,” in Proceedings of the International Conference on Software Maintenance 1998 (ICSM ’98), 1998, pp. 190–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Itkonen</author>
<author>M Hillebrand</author>
<author>V Lappalainen</author>
</authors>
<title>Application of relation analysis to a small java software,”</title>
<date>2004</date>
<booktitle>in Proceedings of the Conference on Software Maintenance and Reengineering (CSMR</booktitle>
<pages>233--239</pages>
<contexts>
<context position="1585" citStr="[3]" startWordPosition="236" endWordPosition="236">ich summarize the changes. We apply our approach on two large case studies and show how we can identify groups of related entities and detect bad smells. I. Introduction Software systems need to change over time to cope with the new requirements [1]. As the requirements happen to crosscut the system’s structure, changes will have to be made in multiple places. Understanding how changes appear in the system is important for detecting hidden dependencies between its parts. In the recent period work has been carried out to detect and interpret groups of software entities that change together [2] [3] [4]. Yet, the detection is based on change 1Ninth IEEE Workshop on Empirical Studies of Software Maintenance (WESS 2004) information concerning one property, and is mostly based on file level information. We propose an approach which detects evolutionary groups based on more than one property. We first define a history meta model and based on this meta model we define historical measurements which summarize the evolution of entities. We use these measurements to detect changes between two versions, and build an Evolution Matrix [5] annotated with changes. We use the matrix as an incidence tab</context>
<context position="13584" citStr="[3]" startWordPosition="2236" endWordPosition="2236">a Home and an Object component. V. Implementation: Moose, Van and ConAn We carried the experiments using a combination of tools: • Van is our version analysis tool. It implements the history meta model (Hismo) and is built on top of Moose[8]. • ConAn is a concept analysis developed on top of Moose. VI. Related Work The first work to study the entities that change together was performed by Gall et al. [2]. The authors use the change information to define a proximity measurements which they use to cluster related entities. The work has been followed up by the same authors [9] and by Itko et al. [3]. Shirabad et al. employ machine learning techniques to detect files which are likely to need to be changed when a particular file is changed [10]. As opposite with the previous approaches, Zimmerman et al. placed their analysis at the level of entities in the meta model [4]. Their focus was to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”. Their approach differs from ours because they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach takes into consideration d</context>
</contexts>
<marker>[3]</marker>
<rawString>J. Itkonen, M. Hillebrand, and V. Lappalainen, “Application of relation analysis to a small java software,” in Proceedings of the Conference on Software Maintenance and Reengineering (CSMR 2004), 2004, pp. 233–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zimmermann</author>
<author>P Weißgerber</author>
<author>S Diehl</author>
<author>A Zeller</author>
</authors>
<title>Mining version histories to guide software changes,”</title>
<date>2004</date>
<booktitle>in 26th International Conference on Software Engineering (ICSE</booktitle>
<contexts>
<context position="1589" citStr="[4]" startWordPosition="237" endWordPosition="237">summarize the changes. We apply our approach on two large case studies and show how we can identify groups of related entities and detect bad smells. I. Introduction Software systems need to change over time to cope with the new requirements [1]. As the requirements happen to crosscut the system’s structure, changes will have to be made in multiple places. Understanding how changes appear in the system is important for detecting hidden dependencies between its parts. In the recent period work has been carried out to detect and interpret groups of software entities that change together [2] [3] [4]. Yet, the detection is based on change 1Ninth IEEE Workshop on Empirical Studies of Software Maintenance (WESS 2004) information concerning one property, and is mostly based on file level information. We propose an approach which detects evolutionary groups based on more than one property. We first define a history meta model and based on this meta model we define historical measurements which summarize the evolution of entities. We use these measurements to detect changes between two versions, and build an Evolution Matrix [5] annotated with changes. We use the matrix as an incidence table f</context>
<context position="13859" citStr="[4]" startWordPosition="2283" endWordPosition="2283">veloped on top of Moose. VI. Related Work The first work to study the entities that change together was performed by Gall et al. [2]. The authors use the change information to define a proximity measurements which they use to cluster related entities. The work has been followed up by the same authors [9] and by Itko et al. [3]. Shirabad et al. employ machine learning techniques to detect files which are likely to need to be changed when a particular file is changed [10]. As opposite with the previous approaches, Zimmerman et al. placed their analysis at the level of entities in the meta model [4]. Their focus was to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”. Their approach differs from ours because they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach takes into consideration different changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no implementation evidence [11]. Detection of problems in the source code structure has long been a main issue in the quality assurance com</context>
</contexts>
<marker>[4]</marker>
<rawString>T. Zimmermann, P. Weißgerber, S. Diehl, and A. Zeller, “Mining version histories to guide software changes,” in 26th International Conference on Software Engineering (ICSE 2004), 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lanza</author>
<author>S Ducasse</author>
</authors>
<title>Understanding software evolution using a combination of software visualization and software metrics,”</title>
<date>2002</date>
<booktitle>in Proceedings of LMO 2002 (Langages et Modeles a Objets,</booktitle>
<pages>135--149</pages>
<contexts>
<context position="2123" citStr="[5]" startWordPosition="320" endWordPosition="320">nterpret groups of software entities that change together [2] [3] [4]. Yet, the detection is based on change 1Ninth IEEE Workshop on Empirical Studies of Software Maintenance (WESS 2004) information concerning one property, and is mostly based on file level information. We propose an approach which detects evolutionary groups based on more than one property. We first define a history meta model and based on this meta model we define historical measurements which summarize the evolution of entities. We use these measurements to detect changes between two versions, and build an Evolution Matrix [5] annotated with changes. We use the matrix as an incidence table for the input into a concept analysis machine which returns the groups of entities that changed certain properties in the same versions. Also, for building the matrix of changes, we make use of logical expressions which combine properties with thresholds and which run on two versions of the system to detect interesting entities. Example. ShotgunSurgery appears when whenever we have to change a class we have to change a number of other classes[6]. We would suspect a group of classes of such a bad smell, when they repeatedly keep t</context>
<context position="4005" citStr="[5]" startWordPosition="642" endWordPosition="642"> on different levels of abstrac2 tions (i.e., method, class, package). We discuss the results we obtained when applying our approach on two large case open source studies, and in the end, we conclude and present the future work. II. History and History Measurements We define a history to be a sequence of versions of the same kind of entity (e.g., class history, system history, etc.). By a version we understand a snapshot of an entity at a certain point in time (e.g., class version, system version, etc.). Example. In the left side of Figure 1 we use a simplified example of the Evolution Matrix [5] to display a system history with 6 versions. A cell in the matrix is marked by a square and represents a class version. A line in the matrix represents a class history and a column represents a system version. In the figure, class A was present in all the version of the system, class B was removed in the last system version while class E appeared in the system only the third system version. Addition of a Version Property (A). We define a generic measurement, called addition of a version property P (A(P, i)), as the addition of that property between version i− 1 and i of the history H: (i &gt; 1)</context>
</contexts>
<marker>[5]</marker>
<rawString>M. Lanza and S. Ducasse, “Understanding software evolution using a combination of software visualization and software metrics,” in Proceedings of LMO 2002 (Langages et Modèles à Objets, 2002, pp. 135–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fowler</author>
<author>K Beck</author>
<author>J Brant</author>
<author>W Opdyke</author>
<author>D Roberts</author>
</authors>
<title>Refactoring: Improving the Design of Existing Code.</title>
<date>1999</date>
<publisher>Addison Wesley,</publisher>
<contexts>
<context position="2637" citStr="[6]" startWordPosition="404" endWordPosition="404">se measurements to detect changes between two versions, and build an Evolution Matrix [5] annotated with changes. We use the matrix as an incidence table for the input into a concept analysis machine which returns the groups of entities that changed certain properties in the same versions. Also, for building the matrix of changes, we make use of logical expressions which combine properties with thresholds and which run on two versions of the system to detect interesting entities. Example. ShotgunSurgery appears when whenever we have to change a class we have to change a number of other classes[6]. We would suspect a group of classes of such a bad smell, when they repeatedly keep their external behavior constant and change the implementation. We can detect this kind of change in a class in the versions in which the number of methods did not change, while the number of statements changed. We can apply our approach on any kind of entities we have in the meta model. In this paper we show how we detect groups of packages, classes and methods. We applied our approach on two large open source case studies. Next, we briefly introduce the notion of history as a first-class entity and define tw</context>
<context position="8538" citStr="[6]" startWordPosition="1417" endWordPosition="1417">ber of methods. The Evolution Matrix on the left is the incident table used as the input for the concept analysis machine which outputs the concept lattice on the right. Parallel Bugs group. Such a group, might give indications of similar implementation which could be factor out. As an implementation measure we used number of statements. ParallelBugs : (Ei(NOS) &gt; 0) ∧ Ei(CY CLO) = 0) (4) B. Class Histories Grouping Expressions Shotgun Surgery. The Shotgun Surgery bad-smell is encountered every time when a change operated in a class involves a lot of small changes to a lot of different classes [6]. We detect this bad smell, by looking at the classes which do not change their interface, but change their implementation together. ShotgunSurgery = (Ei(NOM) = 0 ∧ Ei(NOS) &gt; 0) (5) Parallel Inheritance. Parallel Inheritance is detected in the classes which change their number of children together [6]. Such a characteristic is not necessary a bad smell, but gives indications of a hidden link between two hierarchies. For example, if we detect a main hierarchy and a test hierarchy as being parallel, gives us indication that the tests were developed in parallel with the code. ParallelInheritance </context>
</contexts>
<marker>[6]</marker>
<rawString>M. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts, Refactoring: Improving the Design of Existing Code. Addison Wesley, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T McCabe</author>
</authors>
<title>A measure of complexity,”</title>
<date>1976</date>
<journal>IEEE Transactions on Software Engineering,</journal>
<volume>2</volume>
<pages>308--320</pages>
<contexts>
<context position="5121" citStr="[7]" startWordPosition="845" endWordPosition="845">, as the addition of that property between version i− 1 and i of the history H: (i &gt; 1) Ai(P, H) = { Pi(H)− Pi−1(H), Pi(H)− Pi−1(H) &gt; 0 0, Pi(H)− Pi−1(H) 6 0 (1) Evolution of a Version Property (E). We define a generic measurement, called evolution of a version property P (Ei(P )), as being the absolute difference of that property between version i− 1 and i: (i &gt; 1) Ei(P, H) = |Pi(H)− Pi−1(H) |(2) We instantiate the above mentioned measurements by applying them on different version properties of different types of entities: • Method: NOS (number of statements), CYCLO (MCCabe cyclomatic number [7]). • Class: NOM (number of methods), WNOC (number of all subclasses). • Package: NOCls (number of classes), NOM (number of methods). The E measurement shows a change of a certain property, while the A measurement shows the additions of a certain version property. Thus, these measurements summarize the evolution of properties. III. Grouping Mechanism In the left side of Figure 1 we display an Evolution Matrix in which each square represents a class version and the number inside a square represents the number of methods in that particular class version. A grayed square shows a change in the numb</context>
</contexts>
<marker>[7]</marker>
<rawString>T. McCabe, “A measure of complexity,” IEEE Transactions on Software Engineering, vol. 2, no. 4, pp. 308–320, Dec. 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ducasse</author>
<author>M Lanza</author>
<author>S Tichelaar</author>
</authors>
<title>Moose: an extensible language-independent environment for reengineering objectoriented systems,”</title>
<date>2000</date>
<booktitle>in Proceedings of the Second International Symposium on Constructing Software Engineering Tools (CoSET</booktitle>
<contexts>
<context position="13222" citStr="[8]" startWordPosition="2170" endWordPosition="2170">asses which change their number of children 15 times: ServiceMBeanSupport and JBossTestCase. The interpretation of this group is that the largest hierarchy in JBoss is highly tested. The second group detects a relationship between the EJB interfaces: EJBLocalHome and EJBLocalObject. This is due to the architecture of EJB which requires that a bean has to have a Home and an Object component. V. Implementation: Moose, Van and ConAn We carried the experiments using a combination of tools: • Van is our version analysis tool. It implements the history meta model (Hismo) and is built on top of Moose[8]. • ConAn is a concept analysis developed on top of Moose. VI. Related Work The first work to study the entities that change together was performed by Gall et al. [2]. The authors use the change information to define a proximity measurements which they use to cluster related entities. The work has been followed up by the same authors [9] and by Itko et al. [3]. Shirabad et al. employ machine learning techniques to detect files which are likely to need to be changed when a particular file is changed [10]. As opposite with the previous approaches, Zimmerman et al. placed their analysis at the le</context>
</contexts>
<marker>[8]</marker>
<rawString>S. Ducasse, M. Lanza, and S. Tichelaar, “Moose: an extensible language-independent environment for reengineering objectoriented systems,” in Proceedings of the Second International Symposium on Constructing Software Engineering Tools (CoSET 2000), June 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Gall</author>
<author>M Jazayeri</author>
<author>J Krajewski</author>
</authors>
<title>Cvs release history data for detecting logical couplings,”</title>
<date>2003</date>
<booktitle>in International Workshop on Principles of Software Evolution (IWPSE</booktitle>
<pages>13--23</pages>
<contexts>
<context position="13561" citStr="[9]" startWordPosition="2230" endWordPosition="2230">hat a bean has to have a Home and an Object component. V. Implementation: Moose, Van and ConAn We carried the experiments using a combination of tools: • Van is our version analysis tool. It implements the history meta model (Hismo) and is built on top of Moose[8]. • ConAn is a concept analysis developed on top of Moose. VI. Related Work The first work to study the entities that change together was performed by Gall et al. [2]. The authors use the change information to define a proximity measurements which they use to cluster related entities. The work has been followed up by the same authors [9] and by Itko et al. [3]. Shirabad et al. employ machine learning techniques to detect files which are likely to need to be changed when a particular file is changed [10]. As opposite with the previous approaches, Zimmerman et al. placed their analysis at the level of entities in the meta model [4]. Their focus was to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”. Their approach differs from ours because they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach tak</context>
</contexts>
<marker>[9]</marker>
<rawString>H. Gall, M. Jazayeri, and J. Krajewski, “Cvs release history data for detecting logical couplings,” in International Workshop on Principles of Software Evolution (IWPSE 2003), 2003, pp. 13–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Shirabad</author>
<author>T C Lethbridge</author>
<author>S Matwin</author>
</authors>
<title>Mining the maintenance history of a legacy software system,”</title>
<date>2003</date>
<booktitle>in International Conference on Software Maintenance (ICSM</booktitle>
<pages>95--104</pages>
<contexts>
<context position="13730" citStr="[10]" startWordPosition="2261" endWordPosition="2261">sion analysis tool. It implements the history meta model (Hismo) and is built on top of Moose[8]. • ConAn is a concept analysis developed on top of Moose. VI. Related Work The first work to study the entities that change together was performed by Gall et al. [2]. The authors use the change information to define a proximity measurements which they use to cluster related entities. The work has been followed up by the same authors [9] and by Itko et al. [3]. Shirabad et al. employ machine learning techniques to detect files which are likely to need to be changed when a particular file is changed [10]. As opposite with the previous approaches, Zimmerman et al. placed their analysis at the level of entities in the meta model [4]. Their focus was to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”. Their approach differs from ours because they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach takes into consideration different changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no impleme</context>
</contexts>
<marker>[10]</marker>
<rawString>J. S. Shirabad, T. C. Lethbridge, and S. Matwin, “Mining the maintenance history of a legacy software system,” in International Conference on Software Maintenance (ICSM 2003), 2003, pp. 95– 104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Davey</author>
<author>E Burd</author>
</authors>
<title>Clustering and concept analysis for software evolution,”</title>
<date>2001</date>
<booktitle>in Proceedings of the 4th international Workshop on Principles of Software Evolution (IWPSE</booktitle>
<pages>146--149</pages>
<location>Vienna, Austria,</location>
<contexts>
<context position="14351" citStr="[11]" startWordPosition="2362" endWordPosition="2362">h the previous approaches, Zimmerman et al. placed their analysis at the level of entities in the meta model [4]. Their focus was to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”. Their approach differs from ours because they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach takes into consideration different changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no implementation evidence [11]. Detection of problems in the source code structure has long been a main issue in the quality assurance community. Marinescu [12] detects design flaws by defining detection strategies. Ciupke employed queries usually implemented in Prolog to detect “critical design fragments” [13]. Tourwe et al. also explored the use of logic programming to detect design flaws [14]. vanEmden and Moonen detected bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEm</context>
</contexts>
<marker>[11]</marker>
<rawString>J. Davey and E. Burd, “Clustering and concept analysis for software evolution,” in Proceedings of the 4th international Workshop on Principles of Software Evolution (IWPSE 2001), Vienna, Austria, 2001, pp. 146–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Marinescu</author>
</authors>
<title>Measurement and quality in object-oriented design,”</title>
<date>2002</date>
<tech>Ph.D. Thesis,</tech>
<institution>Department of Computer Science, ”Politehnica” University of Timisoara,</institution>
<contexts>
<context position="14481" citStr="[12]" startWordPosition="2383" endWordPosition="2383">to provide a mechanism to warn developers that: “Programmers who changed these 5 functions also changed. . . ”. Their approach differs from ours because they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach takes into consideration different changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no implementation evidence [11]. Detection of problems in the source code structure has long been a main issue in the quality assurance community. Marinescu [12] detects design flaws by defining detection strategies. Ciupke employed queries usually implemented in Prolog to detect “critical design fragments” [13]. Tourwe et al. also explored the use of logic programming to detect design flaws [14]. vanEmden and Moonen detected bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. </context>
</contexts>
<marker>[12]</marker>
<rawString>R. Marinescu, “Measurement and quality in object-oriented design,” Ph.D. Thesis, Department of Computer Science, ”Politehnica” University of Timişoara, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ciupke</author>
</authors>
<title>Automatic detection of design problems in objectoriented reengineering,”</title>
<date>1999</date>
<booktitle>in Proceedings of TOOLS 30</booktitle>
<pages>18--32</pages>
<location>(USA),</location>
<contexts>
<context position="14633" citStr="[13]" startWordPosition="2403" endWordPosition="2403"> they only look at syntactic changes, while we identify changes based on the semantics of the changes. Furthermore, our approach takes into consideration different changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no implementation evidence [11]. Detection of problems in the source code structure has long been a main issue in the quality assurance community. Marinescu [12] detects design flaws by defining detection strategies. Ciupke employed queries usually implemented in Prolog to detect “critical design fragments” [13]. Tourwe et al. also explored the use of logic programming to detect design flaws [14]. vanEmden and Moonen detected bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. We developed a previous approach to using the history of entities to detect design flaws, but in that case we extended the concept of detection strategi</context>
</contexts>
<marker>[13]</marker>
<rawString>O. Ciupke, “Automatic detection of design problems in objectoriented reengineering,” in Proceedings of TOOLS 30 (USA), 1999, pp. 18–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Mens</author>
<author>T Mens</author>
<author>M Wermelinger</author>
</authors>
<title>Maintaining software through intentional source-code views,”</title>
<date>2002</date>
<booktitle>in Proceedings of SEKE</booktitle>
<pages>289--296</pages>
<publisher>ACM Press,</publisher>
<contexts>
<context position="14719" citStr="[14]" startWordPosition="2418" endWordPosition="2418"> of the changes. Furthermore, our approach takes into consideration different changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no implementation evidence [11]. Detection of problems in the source code structure has long been a main issue in the quality assurance community. Marinescu [12] detects design flaws by defining detection strategies. Ciupke employed queries usually implemented in Prolog to detect “critical design fragments” [13]. Tourwe et al. also explored the use of logic programming to detect design flaws [14]. vanEmden and Moonen detected bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. We developed a previous approach to using the history of entities to detect design flaws, but in that case we extended the concept of detection strategies proposed by Marinescu to take into account the time information and showed how we i</context>
</contexts>
<marker>[14]</marker>
<rawString>K. Mens, T. Mens, and M. Wermelinger, “Maintaining software through intentional source-code views,” in Proceedings of SEKE 2002. ACM Press, 2002, pp. 289–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E van Emden</author>
<author>L Moonen</author>
</authors>
<title>Java quality assurance by detecting code smells,” in</title>
<date>2002</date>
<booktitle>Proc. 9th Working Conf. Reverse Engineering.</booktitle>
<pages>97--107</pages>
<publisher>IEEE Computer Society Press,</publisher>
<contexts>
<context position="14793" citStr="[15]" startWordPosition="2430" endWordPosition="2430">ent changes in the same time. Davey and Burd proposed the usage of concept analysis to detect evolutionary concepts, but there was no implementation evidence [11]. Detection of problems in the source code structure has long been a main issue in the quality assurance community. Marinescu [12] detects design flaws by defining detection strategies. Ciupke employed queries usually implemented in Prolog to detect “critical design fragments” [13]. Tourwe et al. also explored the use of logic programming to detect design flaws [14]. vanEmden and Moonen detected bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. We developed a previous approach to using the history of entities to detect design flaws, but in that case we extended the concept of detection strategies proposed by Marinescu to take into account the time information and showed how we improved the detection [16] [17]. Two of the authors already used historica</context>
</contexts>
<marker>[15]</marker>
<rawString>E. van Emden and L. Moonen, “Java quality assurance by detecting code smells,” in Proc. 9th Working Conf. Reverse Engineering. IEEE Computer Society Press, Oct. 2002, pp. 97–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ratiu</author>
</authors>
<title>Time-based detection strategies,” Master’s thesis,</title>
<date>2003</date>
<institution>Faculty of Automatics and Computer Science, ”Politehnica” University of Timisoara,</institution>
<contexts>
<context position="15345" citStr="[16]" startWordPosition="2516" endWordPosition="2516">detected bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. We developed a previous approach to using the history of entities to detect design flaws, but in that case we extended the concept of detection strategies proposed by Marinescu to take into account the time information and showed how we improved the detection [16] [17]. Two of the authors already used historical information to characterize how changes appear during the history of systems[18]. VII. Conclusions and Future Work Understanding how a system changes can reveal hidden dependencies between different parts of the system. Moreover, such dependencies might reveal bad smells in the design. We proposed the usage of historical information to detect parts of the system that change in the same time, according to different rules. For that, we defined a history meta model and history measurements. Based on this model we built queries which detect differe</context>
</contexts>
<marker>[16]</marker>
<rawString>D. Ratiu, “Time-based detection strategies,” Master’s thesis, Faculty of Automatics and Computer Science, ”Politehnica” University of Timişoara, Sept. 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ratiu</author>
<author>S Ducasse</author>
<author>T Gırba</author>
<author>R Marinescu</author>
</authors>
<title>Using history information to improve design flaws detection,”</title>
<date>2004</date>
<booktitle>in Proceedings of the Conference on Software Maintenance and Reengineering (CSMR</booktitle>
<pages>233--232</pages>
<contexts>
<context position="15350" citStr="[17]" startWordPosition="2517" endWordPosition="2517">ted bad smells by looking at code patterns [15]. These approaches differs from ours because they use only the last version of the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. We developed a previous approach to using the history of entities to detect design flaws, but in that case we extended the concept of detection strategies proposed by Marinescu to take into account the time information and showed how we improved the detection [16] [17]. Two of the authors already used historical information to characterize how changes appear during the history of systems[18]. VII. Conclusions and Future Work Understanding how a system changes can reveal hidden dependencies between different parts of the system. Moreover, such dependencies might reveal bad smells in the design. We proposed the usage of historical information to detect parts of the system that change in the same time, according to different rules. For that, we defined a history meta model and history measurements. Based on this model we built queries which detect different ty</context>
</contexts>
<marker>[17]</marker>
<rawString>D. Ratiu, S. Ducasse, T. Gı̂rba, and R. Marinescu, “Using history information to improve design flaws detection,” in Proceedings of the Conference on Software Maintenance and Reengineering (CSMR 2004), 2004, pp. 233–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Gırba</author>
<author>S Ducasse</author>
<author>M Lanza</author>
</authors>
<title>Yesterday’s weather: Guiding early reverse engineering efforts by summarizing the evolution of changes,”</title>
<date>2004</date>
<booktitle>in 20th International Conference on Software Maintenance (ICSM</booktitle>
<contexts>
<context position="15475" citStr="[18]" startWordPosition="2535" endWordPosition="2535"> the code, while we take into account historical information. Furthermore, vanEmden and Moonen proposed as future research the usage of historical information to detect Shotgun Surgery or Parallel Inheritance. We developed a previous approach to using the history of entities to detect design flaws, but in that case we extended the concept of detection strategies proposed by Marinescu to take into account the time information and showed how we improved the detection [16] [17]. Two of the authors already used historical information to characterize how changes appear during the history of systems[18]. VII. Conclusions and Future Work Understanding how a system changes can reveal hidden dependencies between different parts of the system. Moreover, such dependencies might reveal bad smells in the design. We proposed the usage of historical information to detect parts of the system that change in the same time, according to different rules. For that, we defined a history meta model and history measurements. Based on this model we built queries which detect different types of changes. By applying these queries on every version we obtained an Evolution Matrix annotated with the change informat</context>
</contexts>
<marker>[18]</marker>
<rawString>T. Gı̂rba, S. Ducasse, and M. Lanza, “Yesterday’s weather: Guiding early reverse engineering efforts by summarizing the evolution of changes,” in 20th International Conference on Software Maintenance (ICSM 2004), 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>