<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.021296">
<title confidence="0.555384">
How to Make the Hidden Visible – Code Clone
Presentation Revisited
</title>
<author confidence="0.961108">
Sandro Schulze
</author>
<affiliation confidence="0.997884">
University of Magdeburg
</affiliation>
<email confidence="0.986084">
sanschul@ovgu.de
</email>
<author confidence="0.982875">
Niko Schwarz
</author>
<affiliation confidence="0.998597">
University of Bern
</affiliation>
<email confidence="0.955103">
schwarz@iam.unibe.ch
</email>
<bodyText confidence="0.998414222222222">
Abstract—Nowadays, a slew of clone detection approaches
exists, producing a lot of clone data. This data needs to be
analyzed, either manually or automatically. However, even after
analysis, it is still not trivial to derive conclusions or actions from
the analyzed data. In particular, we argue that it is often unclear
how the cloning information should be presented to the user. We
present our idea of task-oriented clone presentation based on use
cases. We identify five use cases that have to be addressed by
appropriate clone presentation techniques.
</bodyText>
<sectionHeader confidence="0.513645" genericHeader="abstract">
I. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.994161815789474">
Intensive research has been performed on clone detection
and evaluation—presentation is often left as an implementation
detail to implementors. While there is a plethora of visualiza-
tions, current visualizations for code clones are limited [1],
[2] in that they are too narrow to one use case, rather than
supporting the multitude of use cases where cloning informa-
tion is useful, e.g., online clone reporting, quality assessment,
and refactoring. They are rather directed to a certain task for
which they are more or less appropriate.
To present code clones in a way that lets the user take
immediate action, we need to understand the range of actions
available. Therefore, we start our analysis by an overview over
current use cases. We then proceed to show a mapping that
shows for every use case which presentations is appropriate,
and vice versa. While our overview is far from complete, the
objective is to guide tool builders and give an overview over
what is there and how it could be exploited.
II. USE CASES FOR CLONE PRESENTATION
Once code clones have been detected and analyzed, they
must be accessible for further treatment. This step, called clone
presentation, is not an obvious task. First of all, there might
be different stakeholders such as software quality managers
or software developers that need different views (including
different degrees of granularity) on the clones. Second, these
stakeholders want to perform different actions. In the follow-
ing, we identify five use cases that encompass the different
views and treatments of clones.
a) Quality assessment (QA): This use case mainly ap-
pears on the management level. For instance, the stakeholder
wants to have an raw estimation on how the existing clones
affect the overall system quality. Furthermore, the detection of
hot spots, i.e., parts of a system that contain a superior amount
of clones, to define countermeasures is part of this use case.
b) Awareness (AW): This use case describes the fact that
it is important for certain stakeholders, especially developers,
to be aware of existing clones and their relations. During
implementation, a developer has to know when he is changing
a fragment that is part of a clone group, in order to prevent
inconsistent updates.
c) Bug prediction (BP): If a bug has been found in a
clone of a code snippet, then all other clones might be incorrect
as well. Further, if a code snippet is copied from a source to a
destination, a certain similarity between source and destination
is implied. This could be exploited to predict bug occurrence.
d) Quality improvement (QI): This use case encompasses
the removal of clones. This requires refactoring techniques and
proper analysis of the differences between near-miss clones,
in order to to select the correct refactoring.
e) Compliance (CO): This use case encompasses two
issues: First, a stakeholder may be interested in whether or
not code in the systems exists that has been copied from
external sources (e.g., third party libraries), in order to verify
that no licensing terms are being violated. Second, there could
be subsystems that contain secret code that is not allowed to
be used outside pre-defined boundaries.
III. PUTTING THE PIECES TOGETHER
Not all visualizations lend themselves equally well to all
tasks. In the last section we have described use cases that
have to be addressed by an appropriate clone presentation.
However, due to the fact that different approaches are possible
for clone representation and visualization, for each use case
we select only some of the techniques and methods that
could be mentioned. Our selection is the result of an intensive
discussions at Dagstuhl seminar 12071 on clone detection, and
could therefore be considered an expert consensus. In Table I,
we show a compatibility matrix that relates use cases to clone
presentation methods.
Not all visualization methods are mentioned. For a more
comprehensive overview over these, we refer to existing
surveys [4], [5].
We argue that clone visualizations such as SeeSoft views
or TreeMaps are helpful to provide a big picture of the clones
in the system and thus support the use cases QA, AW, and
CO. To this end, a SeeSoft view (cf. Figure 1 (b)) represents
each file as rectangle and each clone as a bar within this
rectangle, indicating its size and position. Additionally, code
</bodyText>
<figure confidence="0.984954">
(a) (b)
(c)
</figure>
<figureCaption confidence="0.998792">
Figure 1. Examples for (a) a tree map, (b) a seesoft view, and (c) a compare view from the clone detection and report part of ConQAT [3]
</figureCaption>
<tableCaption confidence="0.6">
Table I
</tableCaption>
<table confidence="0.993578916666667">
MATRIX SHOWING WHICH CLONE PRESENTATION FEATURE CAN BE USED
FOR WHICH USE CASE.
QA AW BP QI CO
SeeSoft View [6] X X ? X
TreeMap [7] X X X
Source code view X X X
Compare view X X
Links X X
Dashboard X ? X
Filtering/querying/zooming X X
User-generated meta-data X
Revision history X X
</table>
<bodyText confidence="0.972501166666667">
clones that belong to the same clone set have the same color.
As a result, the stakeholder receives an overview of clones
and how they are scattered throughout the system. Similarly,
a TreeMap (cf. Figure 1 (a)) represents each file as rectangle
with information on size and position, relatively to the whole
system. Furthermore, the color indicates whether such a file
contains many clones or not, which enables an easy detection
of so-called hot spots.
In contrast to the previously mentioned visualizations, a
developer requires methods for clone presentation that are
seamlessly integrated in their development process. We pro-
pose that the source code view (as provided by common IDEs)
and a compare view (cf. Figure 1 (c)), providing a face-to-
face comparison of two code clones, are appropriate to fulfill
these demands and thus to support the use cases BP and QI.
For the source code view, we suggest to integrate even more
sophisticated approaches such as linking between correspond-
ing clones. Then, the developer could receive information
on corresponding clones in case he changed a cloned code
fragment. Furthermore, they could be provided with means to
change the corresponding clones consistently. Beyond that, the
compare view can provide even more fine-grained information
such as highlighting the differences of two code clones.
Finally, the aforementioned approaches can be comple-
mented by further presentation techniques. For instance, the
revision history can be exploited to provide evolutionary
information about the clones while user-generated meta-data
(e.g., by tagging the clones) can provide useful insights about
the developer’s view on certain clones.
IV. SUMMARY
We have summarized the most common use cases of clone
detectors and mapped them to visualizations that can display
them to the user. While we do not claim completeness, we
want to stimulate discussion on our categorization of use cases
and the respective clone visualization approaches.
V. ACKNOWLEGMENT
This paper is the result of a working group at a Dagstuhl
seminar on clone management1. We would like to thank
Hamit Abdul Basit, Saman Bazrafshan, Daniel M. German,
Nils Göde, and Martin P. Robillard for fruitful and inspiring
discussions at the Dagstuhl seminar, leading to this position
paper.
</bodyText>
<sectionHeader confidence="0.947058" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.998164285714286">
[1] R. Tairas, J. Gray, and I. Baxter, “Visualization of Clone Detection
Results,” in Eclipse technology eXchange. ACM, 2006, pp. 50–54.
[2] J. Cordy, “Exploring Large-Scale System Similarity Using Incremental
Clone Detection and Live Scatterplots,” in ICPC, 2011, pp. 151–160.
[3] E. Juergens, F. Deissenboeck, and B. Hummel, “CloneDetective - A
Workbench for Clone Detection Research,” in ICSE, 2009, pp. 603–606.
[4] S. Diehl, Software Visualization. Springer, 2007.
[5] C. K. Roy and J. Cordy, “A Survey on Software Clone Detection
Research,” Queen’s University at Kingston, Tech. Rep. 2007-541, 2007.
[6] S. Eick, J. Steffen, and J. Sumner, E.E., “Seesoft – A Tool for Visualizing
Line Oriented Software Statistics ,” IEEE TSE, vol. 18, no. 11, pp. 957–
968, 1992.
[7] B. Johnson, “TreeViz: Treemap Visualization of Hierarchically Structured
Information,” in CHI, 1992, pp. 369–370.
</reference>
<footnote confidence="0.597568">
1http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=12071
</footnote>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.664653">
<title confidence="0.9983775">How to Make the Hidden Visible – Code Clone Presentation Revisited</title>
<author confidence="0.999669">Sandro Schulze</author>
<affiliation confidence="0.999876">University of Magdeburg</affiliation>
<email confidence="0.984261">sanschul@ovgu.de</email>
<author confidence="0.999161">Niko Schwarz</author>
<affiliation confidence="0.999941">University of Bern</affiliation>
<email confidence="0.683811">schwarz@iam.unibe.ch</email>
<abstract confidence="0.999042555555556">Nowadays, a slew of clone detection approaches exists, producing a lot of clone data. This data needs to be analyzed, either manually or automatically. However, even after analysis, it is still not trivial to derive conclusions or actions from the analyzed data. In particular, we argue that it is often unclear how the cloning information should be presented to the user. We present our idea of task-oriented clone presentation based on use cases. We identify five use cases that have to be addressed by appropriate clone presentation techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Tairas</author>
<author>J Gray</author>
<author>I Baxter</author>
</authors>
<date>2006</date>
<booktitle>Visualization of Clone Detection Results,” in Eclipse technology eXchange. ACM,</booktitle>
<pages>50--54</pages>
<contexts>
<context position="992" citStr="[1]" startWordPosition="147" endWordPosition="147">l to derive conclusions or actions from the analyzed data. In particular, we argue that it is often unclear how the cloning information should be presented to the user. We present our idea of task-oriented clone presentation based on use cases. We identify five use cases that have to be addressed by appropriate clone presentation techniques. I. INTRODUCTION Intensive research has been performed on clone detection and evaluation—presentation is often left as an implementation detail to implementors. While there is a plethora of visualizations, current visualizations for code clones are limited [1], [2] in that they are too narrow to one use case, rather than supporting the multitude of use cases where cloning information is useful, e.g., online clone reporting, quality assessment, and refactoring. They are rather directed to a certain task for which they are more or less appropriate. To present code clones in a way that lets the user take immediate action, we need to understand the range of actions available. Therefore, we start our analysis by an overview over current use cases. We then proceed to show a mapping that shows for every use case which presentations is appropriate, and vic</context>
</contexts>
<marker>[1]</marker>
<rawString>R. Tairas, J. Gray, and I. Baxter, “Visualization of Clone Detection Results,” in Eclipse technology eXchange. ACM, 2006, pp. 50–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cordy</author>
</authors>
<title>Exploring Large-Scale System Similarity Using Incremental Clone Detection and Live Scatterplots,”</title>
<date>2011</date>
<booktitle>in ICPC,</booktitle>
<pages>151--160</pages>
<contexts>
<context position="997" citStr="[2]" startWordPosition="148" endWordPosition="148">derive conclusions or actions from the analyzed data. In particular, we argue that it is often unclear how the cloning information should be presented to the user. We present our idea of task-oriented clone presentation based on use cases. We identify five use cases that have to be addressed by appropriate clone presentation techniques. I. INTRODUCTION Intensive research has been performed on clone detection and evaluation—presentation is often left as an implementation detail to implementors. While there is a plethora of visualizations, current visualizations for code clones are limited [1], [2] in that they are too narrow to one use case, rather than supporting the multitude of use cases where cloning information is useful, e.g., online clone reporting, quality assessment, and refactoring. They are rather directed to a certain task for which they are more or less appropriate. To present code clones in a way that lets the user take immediate action, we need to understand the range of actions available. Therefore, we start our analysis by an overview over current use cases. We then proceed to show a mapping that shows for every use case which presentations is appropriate, and vice ver</context>
</contexts>
<marker>[2]</marker>
<rawString>J. Cordy, “Exploring Large-Scale System Similarity Using Incremental Clone Detection and Live Scatterplots,” in ICPC, 2011, pp. 151–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Juergens</author>
<author>F Deissenboeck</author>
<author>B Hummel</author>
</authors>
<title>CloneDetective - A Workbench for Clone Detection Research,”</title>
<date>2009</date>
<booktitle>in ICSE,</booktitle>
<pages>603--606</pages>
<contexts>
<context position="5248" citStr="[3]" startWordPosition="853" endWordPosition="853">tioned. For a more comprehensive overview over these, we refer to existing surveys [4], [5]. We argue that clone visualizations such as SeeSoft views or TreeMaps are helpful to provide a big picture of the clones in the system and thus support the use cases QA, AW, and CO. To this end, a SeeSoft view (cf. Figure 1 (b)) represents each file as rectangle and each clone as a bar within this rectangle, indicating its size and position. Additionally, code (a) (b) (c) Figure 1. Examples for (a) a tree map, (b) a seesoft view, and (c) a compare view from the clone detection and report part of ConQAT [3] Table I MATRIX SHOWING WHICH CLONE PRESENTATION FEATURE CAN BE USED FOR WHICH USE CASE. QA AW BP QI CO SeeSoft View [6] X X ? X TreeMap [7] X X X Source code view X X X Compare view X X Links X X Dashboard X ? X Filtering/querying/zooming X X User-generated meta-data X Revision history X X clones that belong to the same clone set have the same color. As a result, the stakeholder receives an overview of clones and how they are scattered throughout the system. Similarly, a TreeMap (cf. Figure 1 (a)) represents each file as rectangle with information on size and position, relatively to the whole</context>
</contexts>
<marker>[3]</marker>
<rawString>E. Juergens, F. Deissenboeck, and B. Hummel, “CloneDetective - A Workbench for Clone Detection Research,” in ICSE, 2009, pp. 603–606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Diehl</author>
</authors>
<title>Software Visualization.</title>
<date>2007</date>
<publisher>Springer,</publisher>
<contexts>
<context position="4731" citStr="[4]" startWordPosition="757" endWordPosition="757">iate clone presentation. However, due to the fact that different approaches are possible for clone representation and visualization, for each use case we select only some of the techniques and methods that could be mentioned. Our selection is the result of an intensive discussions at Dagstuhl seminar 12071 on clone detection, and could therefore be considered an expert consensus. In Table I, we show a compatibility matrix that relates use cases to clone presentation methods. Not all visualization methods are mentioned. For a more comprehensive overview over these, we refer to existing surveys [4], [5]. We argue that clone visualizations such as SeeSoft views or TreeMaps are helpful to provide a big picture of the clones in the system and thus support the use cases QA, AW, and CO. To this end, a SeeSoft view (cf. Figure 1 (b)) represents each file as rectangle and each clone as a bar within this rectangle, indicating its size and position. Additionally, code (a) (b) (c) Figure 1. Examples for (a) a tree map, (b) a seesoft view, and (c) a compare view from the clone detection and report part of ConQAT [3] Table I MATRIX SHOWING WHICH CLONE PRESENTATION FEATURE CAN BE USED FOR WHICH USE </context>
</contexts>
<marker>[4]</marker>
<rawString>S. Diehl, Software Visualization. Springer, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C K Roy</author>
<author>J Cordy</author>
</authors>
<date>2007</date>
<journal>A Survey on Software Clone Detection Research,” Queen’s University at Kingston, Tech. Rep.</journal>
<contexts>
<context position="4736" citStr="[5]" startWordPosition="758" endWordPosition="758">clone presentation. However, due to the fact that different approaches are possible for clone representation and visualization, for each use case we select only some of the techniques and methods that could be mentioned. Our selection is the result of an intensive discussions at Dagstuhl seminar 12071 on clone detection, and could therefore be considered an expert consensus. In Table I, we show a compatibility matrix that relates use cases to clone presentation methods. Not all visualization methods are mentioned. For a more comprehensive overview over these, we refer to existing surveys [4], [5]. We argue that clone visualizations such as SeeSoft views or TreeMaps are helpful to provide a big picture of the clones in the system and thus support the use cases QA, AW, and CO. To this end, a SeeSoft view (cf. Figure 1 (b)) represents each file as rectangle and each clone as a bar within this rectangle, indicating its size and position. Additionally, code (a) (b) (c) Figure 1. Examples for (a) a tree map, (b) a seesoft view, and (c) a compare view from the clone detection and report part of ConQAT [3] Table I MATRIX SHOWING WHICH CLONE PRESENTATION FEATURE CAN BE USED FOR WHICH USE CASE.</context>
</contexts>
<marker>[5]</marker>
<rawString>C. K. Roy and J. Cordy, “A Survey on Software Clone Detection Research,” Queen’s University at Kingston, Tech. Rep. 2007-541, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Eick</author>
<author>J Steffen</author>
<author>J Sumner</author>
<author>E E</author>
</authors>
<title>Seesoft – A Tool for Visualizing Line Oriented Software Statistics ,”</title>
<date>1992</date>
<journal>IEEE TSE,</journal>
<volume>18</volume>
<pages>957--968</pages>
<contexts>
<context position="5368" citStr="[6]" startWordPosition="876" endWordPosition="876">zations such as SeeSoft views or TreeMaps are helpful to provide a big picture of the clones in the system and thus support the use cases QA, AW, and CO. To this end, a SeeSoft view (cf. Figure 1 (b)) represents each file as rectangle and each clone as a bar within this rectangle, indicating its size and position. Additionally, code (a) (b) (c) Figure 1. Examples for (a) a tree map, (b) a seesoft view, and (c) a compare view from the clone detection and report part of ConQAT [3] Table I MATRIX SHOWING WHICH CLONE PRESENTATION FEATURE CAN BE USED FOR WHICH USE CASE. QA AW BP QI CO SeeSoft View [6] X X ? X TreeMap [7] X X X Source code view X X X Compare view X X Links X X Dashboard X ? X Filtering/querying/zooming X X User-generated meta-data X Revision history X X clones that belong to the same clone set have the same color. As a result, the stakeholder receives an overview of clones and how they are scattered throughout the system. Similarly, a TreeMap (cf. Figure 1 (a)) represents each file as rectangle with information on size and position, relatively to the whole system. Furthermore, the color indicates whether such a file contains many clones or not, which enables an easy detecti</context>
</contexts>
<marker>[6]</marker>
<rawString>S. Eick, J. Steffen, and J. Sumner, E.E., “Seesoft – A Tool for Visualizing Line Oriented Software Statistics ,” IEEE TSE, vol. 18, no. 11, pp. 957– 968, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Johnson</author>
</authors>
<title>TreeViz: Treemap Visualization of Hierarchically Structured Information,”</title>
<date>1992</date>
<booktitle>in CHI,</booktitle>
<pages>369--370</pages>
<contexts>
<context position="5388" citStr="[7]" startWordPosition="882" endWordPosition="882">oft views or TreeMaps are helpful to provide a big picture of the clones in the system and thus support the use cases QA, AW, and CO. To this end, a SeeSoft view (cf. Figure 1 (b)) represents each file as rectangle and each clone as a bar within this rectangle, indicating its size and position. Additionally, code (a) (b) (c) Figure 1. Examples for (a) a tree map, (b) a seesoft view, and (c) a compare view from the clone detection and report part of ConQAT [3] Table I MATRIX SHOWING WHICH CLONE PRESENTATION FEATURE CAN BE USED FOR WHICH USE CASE. QA AW BP QI CO SeeSoft View [6] X X ? X TreeMap [7] X X X Source code view X X X Compare view X X Links X X Dashboard X ? X Filtering/querying/zooming X X User-generated meta-data X Revision history X X clones that belong to the same clone set have the same color. As a result, the stakeholder receives an overview of clones and how they are scattered throughout the system. Similarly, a TreeMap (cf. Figure 1 (a)) represents each file as rectangle with information on size and position, relatively to the whole system. Furthermore, the color indicates whether such a file contains many clones or not, which enables an easy detection of so-called hot </context>
</contexts>
<marker>[7]</marker>
<rawString>B. Johnson, “TreeViz: Treemap Visualization of Hierarchically Structured Information,” in CHI, 1992, pp. 369–370.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>