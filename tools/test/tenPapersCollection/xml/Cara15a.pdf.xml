<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000043">
<title confidence="0.9428415">
A Unified Approach to Automatic Testing of
Architectural Constraints
</title>
<author confidence="0.978867">
Andrea Caracciolo
</author>
<affiliation confidence="0.946643">
Software Composition Group, University of Bern, Switzerland
</affiliation>
<email confidence="0.646984">
caracciolo@iam.unibe.ch Ã¢ÂÂ http://scg.unibe.ch
</email>
<bodyText confidence="0.999316230769231">
AbstractÃ¢ÂÂArchitectural decisions are often encoded in the
form of constraints and guidelines. Non-functional requirements
can be ensured by checking the conformance of the implemen-
tation against this kind of invariant. Conformance checking is
often a costly and error-prone process that involves the use of
multiple tools, differing in effectiveness, complexity and scope of
applicability. To reduce the overall effort entailed by this activity,
we propose a novel approach that supports verification of human-
readable declarative rules through the use of adapted off-the-
shelf tools. Our approach consists of a rule specification DSL,
called DictoÃÂ, and a tool coordination framework, called ProboÃÂ.
The approach has been implemented in a soon to be evaluated
prototype.
</bodyText>
<sectionHeader confidence="0.514555" genericHeader="abstract">
I. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.985634673913043">
Software architecture is generally conceived as the set of
principal design decisions governing a system [1]. Architec-
tural decisions are often undocumented and, at best, become
visible to stakeholders in the form of written guidelines and
implementation constraints. To verify architectural compli-
ance, and consequently prevent architectural drift and erosion
[2], we need to check whether the implementation is in
conformance with its architecture. This can be done with a
multitude of tools (See section II). Unfortunately, as confirmed
by our previous study [3], automated tool-based conformance
checking of architectural constraints is not common-place.
On average, about 60% of practitioners adopt non-automated
techniques (e.g., code review or manual testing) or avoid
testing completely [3]. This is partially due to:
Ã¢ÂÂ¢ Fragmented tool support: Current automated testing
tools are highly specialized and can typically handle at
most one type of architectural constraint.
Ã¢ÂÂ¢ Tool incompatibility: Each solution is based on a
uniquely devised conceptual model and operates accord-
ing to its own technical and theoretical assumptions. The
absence of a common standard specification language
prevents interoperability and forces the user to deal with
a growing number of relatively inconsistent notations.
Ã¢ÂÂ¢ Steep learning curve: Many tools require a considerable
amount of time to be properly utilized. This might be
complicated by the lack of proper documentation or
general usability flaws.
All these points contribute to increasing the overall cost of
selecting, setting up and operating a complete environment for
continuously assessing the conformance of a system with a set
of user-specified architectural constraints. This high cost often
contributes in making architectural checking a sporadic and
undervalued activity.
Our goal is to reduce the overall effort required to check
architectural constraints by proposing:
Ã¢ÂÂ¢ A Business-Readable DSL that can be used to specify
a wide range of architectural rules;
Ã¢ÂÂ¢ A Tool Integration Framework that enables users to
verify custom defined rules using third-party tools.
Our approach is described in more detail in previous pub-
lications [4], [5], [6] and in the remainder of this paper.
A working implementation of the proposed solution can be
downloaded from our website1. The proposed prototype is an
integrated automated architectural testing solution that accepts
declaratively specified rules and checks for system compliance
by interfacing with third-party tools.
</bodyText>
<sectionHeader confidence="0.667016" genericHeader="categories and subject descriptors">
II. RELATED WORK
</sectionHeader>
<bodyText confidence="0.996148571428571">
Many approaches have been proposed for describing and
checking architectural properties and structures.
ADLs are domain specific languages designed to capture
the main concerns of one or more architectural views in
a single uniform textual specification. Among the different
solutions that can be found in literature [7], [8], [9], only
few have practical relevance. Analyzability and tool support
are key features of an ADL [10], [11]. Unfortunately the
vast majority of ADLs offer very limited or no support for
evaluating the alignment between intended (as defined in a
model) and concrete architecture (as implemented in a system).
Some ADLs (e.g., UML 2.0 [12]) could potentially be used to
drive testing activities. Unfortunately, the absence of a shared
and widely applicable set of tools and practices prevents the
usage of such languages in a common industrial context.
Somebody wanting to get around this limitation is therefore
required to adopt one of the existing academic and commercial
conformance testing tools. These tools are typically specialized
on a smaller, but therefore also more clearly defined, domain.
Most of them are designed to evaluate module dependencies
[13], [14] and performance (e.g., JMeter2, DynaTrace3, Load-
</bodyText>
<footnote confidence="0.850575666666667">
Runner4). Meta-tools (e.g., Moose [15], IntensiVe [16]) can
be used to build custom analyzers for verifying structural
1http://scg.unibe.ch/dicto/
2http://jmeter.apache.org
3http://www.dynatrace.com
4http://www8.hp.com/us/en/software-solutions/loadrunner-load-testing/
</footnote>
<bodyText confidence="0.97707172">
properties. As explained in the introduction, these solutions
come with various disadvantages that make their adoption
costly and impractical.
In order to offer a suitable, comprehensive and economical
solution to conformance checking, we propose a new testing
approach consisting of a business-readable rule specification
DSL, called DictoÃÂ, and a tool coordination framework, called
ProboÃÂ. This approach gives access to the functionality of
existing analysis tools without requiring the user to acquire
any of the technical and operational skills which he would
need to be possess if he had to interact with the same tools
directly.
III. OUR APPROACH
The main advantages of our approach can be synthesized
as:
Ã¢ÂÂ¢ Uniform specification language: a wide range of ar-
chitectural concerns can be described using a single,
declarative language, called DictoÃÂ.
Ã¢ÂÂ¢ Incremental specification: the architecture can be de-
scribed incrementally by means of rules which typically
address a specific aspect of the overall design.
Ã¢ÂÂ¢ Modular architecture: user-specified rules are inter-
preted by a modular tool integration framework, called
ProboÃÂ. Developers can add support for new analyses and
concepts by developing plugins.
</bodyText>
<figure confidence="0.980546083333333">
Stack: Class with name=Ã¢ÂÂcom.*.IStackÃ¢ÂÂ
Stack must have method Ã¢ÂÂpush(Item)Ã¢ÂÂ, Ã¢ÂÂItem pull()Ã¢ÂÂ
HasMethod(com.xyz.IStack, Ã¢ÂÂpush(Item)Ã¢ÂÂ)
HasMethod(com.abc.IStack, Ã¢ÂÂpush(Item)Ã¢ÂÂ)
HasMethod(Ã¢ÂÂ¦)
Evaluator
[
1
2
3
]
Dicto rules
</figure>
<figureCaption confidence="0.7062465">
Fig. 1. Approach overview: (1) rule normalization and predicate definition
(2) predicate evaluation (3) report generation
</figureCaption>
<bodyText confidence="0.983415894736842">
Figure 1 shows a high-level overview of the approach. The
process, as described in the picture, is described in more detail
in the following two sections.
A. DictoÃÂ: A Business-Readable DSL
In our approach, architectural constraints are specified in a
human-readable declarative DSL, called DictoÃÂ. This language
was designed based on observations gathered during a previous
empirical study (consisting of 14 interviews and a survey with
34 responses)[3]. In this study we analyzed how quality re-
quirements are defined and validated by practitioners. Among
other things, we discovered that many user-specified guidelines
reflect a common structure. A guideline typically describes a
set of artifacts (e.g., Ã¢ÂÂBusiness Service interfaces and imple-
mentations ..Ã¢ÂÂ) and various constraints that are defined on them
(e.g., Ã¢ÂÂ.. must end with *ServiceÃ¢ÂÂ). From these two concepts,
we designed a language that is generic enough to be used for
describing most of the architectural constraints encountered in
practice (e.g., performance, security, coding conventions).
To better understand how to use DictoÃÂ, we describe a simple
</bodyText>
<listItem confidence="0.9330596">
scenario in which we evaluate package dependencies.
E1) Controller: Package with name=&amp;quot;*.Controller&amp;quot;
E2) Model: Package with name=&amp;quot;*.Model&amp;quot;
R1) only Controller, Model can depend on Model
R2) Controller must depend on Model
</listItem>
<bodyText confidence="0.985209333333333">
In the above presented example, we define two entities
(statements E1, E2) and two rules (R1, R2). Entities are auto-
matically mapped to corresponding concrete elements existing
in the system under analysis. In our example, we assume
that Controller and Model are matched to two packages as
illustrated in Figure 2.
</bodyText>
<figure confidence="0.947415833333333">
org.Model
org.View
org.TestModel
Controller
ALL_PACKAGES
org.Controller
</figure>
<figureCaption confidence="0.995021">
Fig. 2. Packages contained in a hypothetical system considered in our example
</figureCaption>
<subsectionHeader confidence="0.684385">
Rules can be of different kinds (must, cannot, only ... can,
</subsectionHeader>
<bodyText confidence="0.900537636363636">
can only). In addition to the kind, they have one or multiple
subjects (e.g., Controller, Model in R1), a predicate identifier
(e.g., depend on in R1) and one or multiple predicate argu-
ments (e.g., Model in R1). User-specified rules are normalized
by applying a set of pre-defined syntactic transformations (not
described due to space limitations). In this example, R1 is first
transformed into {R1a, R1b} and afterwards in {R1aÃ¢ÂÂ² , R1bÃ¢ÂÂ²}.
R1a) only Controller can depend on Model
R1b) only Model can depend on Model
R1aÃ¢ÂÂ² ) Controller cannot depend on Model
R1bÃ¢ÂÂ² ) Model cannot depend on Model
</bodyText>
<page confidence="0.911398">
5
</page>
<bodyText confidence="0.9922222">
The goal of normalization is to obtain more managable rules
having only one subject, and one predicate argument. Each of
the normalized rules is then used to produce a set of checkable
predicates. In our example, predicate Pix.n (where i={1,2},
x={a,b}, nÃ¢ÂÂ N) is generated from rule RixÃ¢ÂÂ² or Rix.
</bodyText>
<equation confidence="0.999542">
5Controller = ALL PACKAGES / {org.Controller}
Model = ALL PACKAGES / {org.Model}
P1a.1) dependOn(org.View, org.Model)
P1a.2) dependOn(org.Test, org.Model)
P1a.3) dependOn(org.Model, org.Model)
P1b.1) dependOn(org.View, org.Model)
P1b.2) dependOn(org.Test, org.Model)
P1b.4) dependOn(org.Controller, org.Model)
P2.4) dependOn(org.Controller, org.Model)
</equation>
<bodyText confidence="0.939607709677419">
Each predicate is a boolean function and will be evaluated
based on the results obtained by an external analysis tool.
Predicate results are the basic units of information needed to
decide whether a certain user-specified rule passes or fails. The
failing condition associated to each rule varies according to the
kind of the rule. In our example, rule R1 will fail whenever
a predicate, associated to both of the derived sub-rules R1aÃ¢ÂÂ²
and R1bÃ¢ÂÂ² , evaluates to True. Rule R2 will fail if one of the
derived predicates is found to be false.
fail-condition(R1): Ã¢ÂÂp Ã¢ÂÂ pred(R1aÃ¢ÂÂ² ) Ã¢ÂÂ© pred(R1bÃ¢ÂÂ² ) : ÃÂ»(p) = T
fail-condition(R2): Ã¢ÂÂp Ã¢ÂÂ pred(R2) : ÃÂ»(p) = F
B. ProboÃÂ: A Tool Integration Framework
An essential part of our framework are the adapters that
enable communication with external tools. As we said, pred-
icates are evaluated based on the results provided by these
third-party analyzers. These tools are standalone, open source
programs with a command-line interface. The tool must be
able to automatically produce a textual result based on the
information (e.g., task configuration, scope of analysis) given
as input. External tools are integrated into our solution though
plugins that are capable of interpreting the data contained in
our model and produce a valid enquiry for the tool they adapt.
Plugins must declare which predicates they are capable of
handling, and extend a common interface that prescribes a set
of basic operations (i.e., defining an input file, creating a run
script and interpreting the result output). If these operations
have been correctly defined, we are capable of interacting with
the tool and feed back the obtained results into our model.
In our example we will assume that the results returned
by the third-party analysis tool selected for the userÃ¢ÂÂs ruleset
could be interpreted as follows.
</bodyText>
<equation confidence="0.999837">
P.1) dependOn(org.View, org.Model) = F
P.2) dependOn(org.Test, org.Model) = T
P.3) dependOn(org.Model, org.Model) = T
P.4) dependOn(org.Controller, org.Model) = T
</equation>
<bodyText confidence="0.989357">
If we consider the previously defined failing condition, we
can see that R1 fails because of the following fact.
</bodyText>
<equation confidence="0.999524">
P2 = T Ã¢ÂÂ§ P2 Ã¢ÂÂ predicates(R1a) Ã¢ÂÂ© predicates(R1b)
</equation>
<bodyText confidence="0.988346701754386">
The fail-condition invariant defined for the second rule is
not verified, and therefore R2 does not fail.
All outcomes obtained through the described process are
finally aggregated into a single report for the user.
IV. PRACTICAL APPLICATIONS
Our approach can help reduce the overall effort required to
check the architectural consistency of a system compared to a
given set of guidelines. Architectural rules are specified in a
simple and approachable language designed to resemble cur-
rent specification practices. Rules could therefore be included
in SRS documents to formalize invariants which are typically
expressed in natural language. This would allow for more
stakeholders to take part in the definition of the architecture, by
exposing significant invariants to less-technical stakeholders.
Once written, rules can be directly evaluated without any
additional input from the user.
If one of the rules is not yet supported by the system, a new
adapter needs to be developed. The adapter may be context-
specific or generally applicable. In the latter case, the user may
decide to share his contribution with a larger community by
submitting the code to a public repository.
Automated rule evaluation could be triggered periodically
by including our solution as a step of a continuos integration
process. The results derived from the execution could be
reported in a dashboard (e.g., Sonraqube6) or displayed as
warnings in the IDE. Our aim is to provide accurate feedback
to developers and make them aware of documented (yet often
ignored) design guidelines.
Our approach could also be used to define a list of work
items in the context of an architectural migration project. In
this case, the user would need to define a set of rules that
reflect the target architecture and consider all entities reported
in the results as candidates for refactoring. By following this
strategy, one can keep an overview of the progress and pinpoint
the components of the system that still need to be migrated.
In the future we also plan to experiment different ways
for assigning priorities to rules. This would help users to
distinguish critical violations from less important warnings.
The criticality of a rule could be defined depending on histor-
ical events (e.g., last violation, definition), semantic relations
(e.g., a violation has a negative impact on the outcome of
other related rules) or a user defined classifications (e.g., rule-
specific annotations).
V. ASSESSING APPLICABILITY AND RELEVANCE
We plan to assess the applicability and relevance of our
approach through empirical evaluation. We intend to focus on
the following points:
Ã¢ÂÂ¢ Suitability We want to verify whether our approach is
general enough to fulfill the needs of a wide variety of
users. To evaluate this point we aim at contacting some of
our industrial partners and guide them towards integrating
Dicto in their workflow. This will help us to discover
possible limitations and improve our approach.
Ã¢ÂÂ¢ Flexibility We want to evaluate the effort involved in
creating an adaptor for a new analysis tool. Following the
strategy mentioned in the previous point (i.e., integrating
Dicto in the context of an industrial project), we plan to
</bodyText>
<footnote confidence="0.635104">
6http://www.sonarqube.org
</footnote>
<bodyText confidence="0.992060150943396">
uncover the difficulties arising in the process of adapting
the approach to the needs of a real customer.
Ã¢ÂÂ¢ Usability Finally, we want to see how intuitive our
approach might appear to a typical end-user. We would
like to confront various types of stakeholders with a
written specification of some rules and ask them to
perform simple tasks (e.g., modify a rule, define a new
entity).
Ã¢ÂÂ¢ Reusability We would like to verify how often users
need to adapt custom defined analyzers compared to
reusing pre-defined ones. By interacting with real users
and discussing their needs we want to measure the actual
effort required to obtain a meaningful solution in terms
of customization steps. We might decide to uncover
commonalities in requirements by comparing the answers
of a survey.
We are currently working towards integrating Dicto into the
development process of a major open-source project (Ilias7).
Our partners are interested in monitoring architectural integrity
and supporting developers in the process of identifying rele-
vant candidates for refactoring.
VI. PROGRESS AND MILESTONES
We published a study to discover how software architects
specify and validate quality requirements [3]. Through this
study we reached a better understanding of the needs and prac-
tices currently employed in industry. As a consequence, we
devised a novel approach (described in section III) that aims at
reducing the cost of conformance checking. Our current proto-
type supports various type of rules (e.g., dependencies, website
load/performance, code clones, deadlock-freeness) evaluated
through various analysis tool (e.g., JMeter, JavaPathFinder,
Moose, PMD). We plan to complete the empirical evaluation
of our approach (as described in section V) within the first half
of 2015. The results gathered throughout the process should
appear in the second half of the same year.
VII. CONCLUSION
We presented a novel approach that aims at optimizing
the cost of setting-up and running architectural conformance
checks. The goal of this project is to enable developers and
other stakeholders to quickly and efficiently analyze, main-
tain and evolve complex software systems with the help of
automated tools. By writing executable documentation using
a simple declarative language, we gain a clean separation
between conceptual activities (i.e., design reasoning) and more
technical tasks (i.e., dealing with testing tools).
Our approach is both convenient and flexible. Users can
conveniently exploit the functionality of off-the-shelf testing
solutions without dealing with any tool or configuration pro-
cess. The approach is also based on an extensible plugin-based
integration framework which facilitates the addition of new
rules and analyzers.
We plan to evaluate the applicability and relevance of our
approach by collaborating with various industrial partners.
</bodyText>
<footnote confidence="0.935651">
7http://www.ilias.de
</footnote>
<sectionHeader confidence="0.888091" genericHeader="acknowledgments">
ACKNOWLEDGMENT
</sectionHeader>
<bodyText confidence="0.773919">
I would like to thank Prof. Oscar Nierstrasz and Dr. Mircea
Lungu for their valuable advices and competent supervision.
I gratefully acknowledge the financial support of the Swiss
</bodyText>
<table confidence="0.858403">
National Science Foundation for the project Ã¢ÂÂAgile Software
AssessmentÃ¢ÂÂ (SNSF project Np. 200020-144126/1, Jan 1, 2013
- Dec. 30, 2015).
</table>
<sectionHeader confidence="0.914635" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999579411764706">
[1] R. N. Taylor, N. Medvidovic, and E. M. Dashofy, Software Architecture:
Foundations, Theory, and Practice. New York, NY, USA: Wiley, Jan.
2009.
[2] D. E. Perry and A. L. Wolf, Ã¢ÂÂFoundations for the study of software
architecture,Ã¢ÂÂ ACM SIGSOFT Software Engineering Notes, vol. 17,
pp. 40Ã¢ÂÂ52, Oct. 1992.
[3] A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂHow do software
architects specify and validate quality requirements?,Ã¢ÂÂ in European
Conference on Software Architecture (ECSA), vol. 8627 of Lecture Notes
in Computer Science, pp. 374Ã¢ÂÂ389, Springer Berlin Heidelberg, Aug.
2014.
[4] A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂDicto: A unified DSL
for testing architectural rules,Ã¢ÂÂ in Proceedings of the 2014 European
Conference on Software Architecture Workshops, ECSAW Ã¢ÂÂ14, (New
York, NY, USA), pp. 21:1Ã¢ÂÂ21:4, ACM, 2014.
[5] A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂDicto: Keeping software
architecture under control,Ã¢ÂÂ ERCIM News, vol. 99, Oct. 2014.
[6] A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂA unified approach to
architecture conformance checking,Ã¢ÂÂ in Proceedings of the 12th Working
IEEE/IFIP Conference on Software Architecture (WICSA), ACM Press,
2015. To appear.
[7] R. Allen and D. Garlan, Ã¢ÂÂThe Wright architectural specification lan-
guage,Ã¢ÂÂ CMU-CS-96-TB, School of Computer Science, Carnegie Mellon
University, Pittsburgh, Sept. 1996.
[8] D. C. Luckham and J. Vera, Ã¢ÂÂAn event-based architecture definition lan-
guage,Ã¢ÂÂ IEEE Transactions on Software Engineering, vol. 21, pp. 717Ã¢ÂÂ
734, Sept. 1995.
[9] P. H. Feiler, D. P. Gluch, and J. J. Hudak, Ã¢ÂÂThe architecture analysis &amp;
design language (AADL): An introduction,Ã¢ÂÂ tech. rep., DTIC Document,
2006.
[10] N. Medvidovic, E. M. Dashofy, and R. N. Taylor, Ã¢ÂÂMoving architectural
description from under the technology lamppost,Ã¢ÂÂ Information and
Software Technology, vol. 49, no. 1, pp. 12Ã¢ÂÂ31, 2007.
[11] I. Malavolta, P. Lago, H. Muccini, P. Pelliccione, and A. Tang, Ã¢ÂÂWhat
industry needs from architectural languages: A survey,Ã¢ÂÂ Software Engi-
neering, IEEE Transactions on, vol. 39, no. 6, pp. 869Ã¢ÂÂ891, 2013.
[12] G. Booch, J. Rumbaugh, and I. Jacobson, The Unified Modeling Lan-
guage User Guide. Reading, Mass.: Addison Wesley, second ed., 2005.
[13] J. Knodel, D. Muthig, M. Naab, and M. Lindvall, Ã¢ÂÂStatic evaluation
of software architectures,Ã¢ÂÂ in CSMRÃ¢ÂÂ06, (Los Alamitos, CA, USA),
pp. 279Ã¢ÂÂ294, IEEE Computer Society, 2006.
[14] W. Bischofberger, J. KuÃÂhl, and S. LoÃÂffler, Ã¢ÂÂSotograph Ã¢ÂÂ a pragmatic ap-
proach to source code architecture conformance checking,Ã¢ÂÂ in Software
Architecture, vol. 3047 of LNCS, pp. 1Ã¢ÂÂ9, Springer-Verlag, 2004.
[15] S. Ducasse, T. GÃÂ±ÃÂrba, and O. Nierstrasz, Ã¢ÂÂMoose: an agile reengineering
environment,Ã¢ÂÂ in Proceedings of ESEC/FSE 2005, pp. 99Ã¢ÂÂ102, Sept.
2005. Tool demo.
[16] K. Mens and A. Kellens, Ã¢ÂÂIntensiVE, a toolsuite for documenting and
checking structural source-code regularities,Ã¢ÂÂ in Software Maintenance
and Reengineering, 2006. CSMR 2006. Proceedings of the 10th Euro-
pean Conference on, pp. 10 pp. Ã¢ÂÂ248, mar 2006.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.107755">
<title confidence="0.9994105">A Unified Approach to Automatic Testing of Architectural Constraints</title>
<author confidence="0.999889">Andrea Caracciolo</author>
<affiliation confidence="0.600534">Software Composition Group, University of Bern, Switzerland</affiliation>
<abstract confidence="0.876946285714286">caracciolo@iam.unibe.ch Ã¢ÂÂ http://scg.unibe.ch AbstractÃ¢ÂÂArchitectural decisions are often encoded in the form of constraints and guidelines. Non-functional requirements can be ensured by checking the conformance of the implementation against this kind of invariant. Conformance checking is often a costly and error-prone process that involves the use of multiple tools, differing in effectiveness, complexity and scope of applicability. To reduce the overall effort entailed by this activity, we propose a novel approach that supports verification of humanreadable declarative rules through the use of adapted off-theshelf tools. Our approach consists of a rule specification DSL, called DictoÃÂ, and a tool coordination framework, called ProboÃÂ. The approach has been implemented in a soon to be evaluated prototype.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R N Taylor</author>
<author>N Medvidovic</author>
<author>E M Dashofy</author>
</authors>
<title>Software Architecture: Foundations, Theory, and Practice.</title>
<date>2009</date>
<publisher>Wiley,</publisher>
<location>New York, NY, USA:</location>
<contexts>
<context position="1093" citStr="[1]" startWordPosition="151" endWordPosition="151">es the use of multiple tools, differing in effectiveness, complexity and scope of applicability. To reduce the overall effort entailed by this activity, we propose a novel approach that supports verification of humanreadable declarative rules through the use of adapted off-theshelf tools. Our approach consists of a rule specification DSL, called DictoÃ, and a tool coordination framework, called ProboÃ. The approach has been implemented in a soon to be evaluated prototype. I. INTRODUCTION Software architecture is generally conceived as the set of principal design decisions governing a system [1]. Architectural decisions are often undocumented and, at best, become visible to stakeholders in the form of written guidelines and implementation constraints. To verify architectural compliance, and consequently prevent architectural drift and erosion [2], we need to check whether the implementation is in conformance with its architecture. This can be done with a multitude of tools (See section II). Unfortunately, as confirmed by our previous study [3], automated tool-based conformance checking of architectural constraints is not common-place. On average, about 60% of practitioners adopt non-</context>
</contexts>
<marker>[1]</marker>
<rawString>R. N. Taylor, N. Medvidovic, and E. M. Dashofy, Software Architecture: Foundations, Theory, and Practice. New York, NY, USA: Wiley, Jan. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Perry</author>
<author>A L Wolf</author>
</authors>
<title>Ã¢Foundations for the study of software architecture,Ã¢</title>
<date>1992</date>
<journal>ACM SIGSOFT Software Engineering Notes,</journal>
<volume>17</volume>
<pages>40--52</pages>
<contexts>
<context position="1349" citStr="[2]" startWordPosition="186" endWordPosition="186">se of adapted off-theshelf tools. Our approach consists of a rule specification DSL, called DictoÃ, and a tool coordination framework, called ProboÃ. The approach has been implemented in a soon to be evaluated prototype. I. INTRODUCTION Software architecture is generally conceived as the set of principal design decisions governing a system [1]. Architectural decisions are often undocumented and, at best, become visible to stakeholders in the form of written guidelines and implementation constraints. To verify architectural compliance, and consequently prevent architectural drift and erosion [2], we need to check whether the implementation is in conformance with its architecture. This can be done with a multitude of tools (See section II). Unfortunately, as confirmed by our previous study [3], automated tool-based conformance checking of architectural constraints is not common-place. On average, about 60% of practitioners adopt non-automated techniques (e.g., code review or manual testing) or avoid testing completely [3]. This is partially due to: Ã¢Â¢ Fragmented tool support: Current automated testing tools are highly specialized and can typically handle at most one type of architect</context>
</contexts>
<marker>[2]</marker>
<rawString>D. E. Perry and A. L. Wolf, Ã¢ÂÂFoundations for the study of software architecture,Ã¢ÂÂ ACM SIGSOFT Software Engineering Notes, vol. 17, pp. 40Ã¢ÂÂ52, Oct. 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Caracciolo</author>
<author>M F Lungu</author>
<author>O Nierstrasz</author>
</authors>
<title>Ã¢How do software architects specify and validate quality requirements?,Ã¢</title>
<date>2014</date>
<booktitle>in European Conference on Software Architecture (ECSA),</booktitle>
<volume>8627</volume>
<pages>374--389</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg,</location>
<contexts>
<context position="1550" citStr="[3]" startWordPosition="219" endWordPosition="219"> evaluated prototype. I. INTRODUCTION Software architecture is generally conceived as the set of principal design decisions governing a system [1]. Architectural decisions are often undocumented and, at best, become visible to stakeholders in the form of written guidelines and implementation constraints. To verify architectural compliance, and consequently prevent architectural drift and erosion [2], we need to check whether the implementation is in conformance with its architecture. This can be done with a multitude of tools (See section II). Unfortunately, as confirmed by our previous study [3], automated tool-based conformance checking of architectural constraints is not common-place. On average, about 60% of practitioners adopt non-automated techniques (e.g., code review or manual testing) or avoid testing completely [3]. This is partially due to: Ã¢Â¢ Fragmented tool support: Current automated testing tools are highly specialized and can typically handle at most one type of architectural constraint. Ã¢Â¢ Tool incompatibility: Each solution is based on a uniquely devised conceptual model and operates according to its own technical and theoretical assumptions. The absence of a common</context>
<context position="7090" citStr="[3]" startWordPosition="1010" endWordPosition="1010">or [ 1 2 3 ] Dicto rules Fig. 1. Approach overview: (1) rule normalization and predicate definition (2) predicate evaluation (3) report generation Figure 1 shows a high-level overview of the approach. The process, as described in the picture, is described in more detail in the following two sections. A. DictoÃ: A Business-Readable DSL In our approach, architectural constraints are specified in a human-readable declarative DSL, called DictoÃ. This language was designed based on observations gathered during a previous empirical study (consisting of 14 interviews and a survey with 34 responses)[3]. In this study we analyzed how quality requirements are defined and validated by practitioners. Among other things, we discovered that many user-specified guidelines reflect a common structure. A guideline typically describes a set of artifacts (e.g., Ã¢Business Service interfaces and implementations ..Ã¢) and various constraints that are defined on them (e.g., Ã¢.. must end with *ServiceÃ¢). From these two concepts, we designed a language that is generic enough to be used for describing most of the architectural constraints encountered in practice (e.g., performance, security, coding con</context>
<context position="16375" citStr="[3]" startWordPosition="2449" endWordPosition="2449">asure the actual effort required to obtain a meaningful solution in terms of customization steps. We might decide to uncover commonalities in requirements by comparing the answers of a survey. We are currently working towards integrating Dicto into the development process of a major open-source project (Ilias7). Our partners are interested in monitoring architectural integrity and supporting developers in the process of identifying relevant candidates for refactoring. VI. PROGRESS AND MILESTONES We published a study to discover how software architects specify and validate quality requirements [3]. Through this study we reached a better understanding of the needs and practices currently employed in industry. As a consequence, we devised a novel approach (described in section III) that aims at reducing the cost of conformance checking. Our current prototype supports various type of rules (e.g., dependencies, website load/performance, code clones, deadlock-freeness) evaluated through various analysis tool (e.g., JMeter, JavaPathFinder, Moose, PMD). We plan to complete the empirical evaluation of our approach (as described in section V) within the first half of 2015. The results gathered </context>
</contexts>
<marker>[3]</marker>
<rawString>A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂHow do software architects specify and validate quality requirements?,Ã¢ÂÂ in European Conference on Software Architecture (ECSA), vol. 8627 of Lecture Notes in Computer Science, pp. 374Ã¢ÂÂ389, Springer Berlin Heidelberg, Aug. 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Caracciolo</author>
<author>M F Lungu</author>
<author>O Nierstrasz</author>
</authors>
<title>Ã¢Dicto: A unified DSL for testing architectural rules,Ã¢</title>
<date>2014</date>
<booktitle>in Proceedings of the 2014 European Conference on Software Architecture Workshops, ECSAW Ã¢14,</booktitle>
<pages>21--1</pages>
<publisher>ACM,</publisher>
<location>(New York, NY, USA),</location>
<contexts>
<context position="3191" citStr="[4]" startWordPosition="460" endWordPosition="460">omplete environment for continuously assessing the conformance of a system with a set of user-specified architectural constraints. This high cost often contributes in making architectural checking a sporadic and undervalued activity. Our goal is to reduce the overall effort required to check architectural constraints by proposing: Ã¢Â¢ A Business-Readable DSL that can be used to specify a wide range of architectural rules; Ã¢Â¢ A Tool Integration Framework that enables users to verify custom defined rules using third-party tools. Our approach is described in more detail in previous publications [4], [5], [6] and in the remainder of this paper. A working implementation of the proposed solution can be downloaded from our website1. The proposed prototype is an integrated automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification</context>
</contexts>
<marker>[4]</marker>
<rawString>A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂDicto: A unified DSL for testing architectural rules,Ã¢ÂÂ in Proceedings of the 2014 European Conference on Software Architecture Workshops, ECSAW Ã¢ÂÂ14, (New York, NY, USA), pp. 21:1Ã¢ÂÂ21:4, ACM, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Caracciolo</author>
<author>M F Lungu</author>
<author>O Nierstrasz</author>
</authors>
<title>Ã¢Dicto: Keeping software architecture under control,Ã¢</title>
<date>2014</date>
<journal>ERCIM News,</journal>
<volume>99</volume>
<contexts>
<context position="3196" citStr="[5]" startWordPosition="461" endWordPosition="461">te environment for continuously assessing the conformance of a system with a set of user-specified architectural constraints. This high cost often contributes in making architectural checking a sporadic and undervalued activity. Our goal is to reduce the overall effort required to check architectural constraints by proposing: Ã¢Â¢ A Business-Readable DSL that can be used to specify a wide range of architectural rules; Ã¢Â¢ A Tool Integration Framework that enables users to verify custom defined rules using third-party tools. Our approach is described in more detail in previous publications [4], [5], [6] and in the remainder of this paper. A working implementation of the proposed solution can be downloaded from our website1. The proposed prototype is an integrated automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Amo</context>
</contexts>
<marker>[5]</marker>
<rawString>A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂDicto: Keeping software architecture under control,Ã¢ÂÂ ERCIM News, vol. 99, Oct. 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Caracciolo</author>
<author>M F Lungu</author>
<author>O Nierstrasz</author>
</authors>
<title>Ã¢A unified approach to architecture conformance checking,Ã¢</title>
<date>2015</date>
<booktitle>in Proceedings of the 12th Working IEEE/IFIP Conference on Software Architecture (WICSA),</booktitle>
<publisher>ACM Press,</publisher>
<note>To appear.</note>
<contexts>
<context position="3201" citStr="[6]" startWordPosition="462" endWordPosition="462">vironment for continuously assessing the conformance of a system with a set of user-specified architectural constraints. This high cost often contributes in making architectural checking a sporadic and undervalued activity. Our goal is to reduce the overall effort required to check architectural constraints by proposing: Ã¢Â¢ A Business-Readable DSL that can be used to specify a wide range of architectural rules; Ã¢Â¢ A Tool Integration Framework that enables users to verify custom defined rules using third-party tools. Our approach is described in more detail in previous publications [4], [5], [6] and in the remainder of this paper. A working implementation of the proposed solution can be downloaded from our website1. The proposed prototype is an integrated automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among th</context>
</contexts>
<marker>[6]</marker>
<rawString>A. Caracciolo, M. F. Lungu, and O. Nierstrasz, Ã¢ÂÂA unified approach to architecture conformance checking,Ã¢ÂÂ in Proceedings of the 12th Working IEEE/IFIP Conference on Software Architecture (WICSA), ACM Press, 2015. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Allen</author>
<author>D Garlan</author>
</authors>
<title>Ã¢The Wright architectural specification language,Ã¢</title>
<date>1996</date>
<tech>CMU-CS-96-TB,</tech>
<institution>School of Computer Science, Carnegie Mellon University,</institution>
<location>Pittsburgh,</location>
<contexts>
<context position="3858" citStr="[7]" startWordPosition="557" endWordPosition="557">ntation of the proposed solution can be downloaded from our website1. The proposed prototype is an integrated automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among the different solutions that can be found in literature [7], [8], [9], only few have practical relevance. Analyzability and tool support are key features of an ADL [10], [11]. Unfortunately the vast majority of ADLs offer very limited or no support for evaluating the alignment between intended (as defined in a model) and concrete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limit</context>
</contexts>
<marker>[7]</marker>
<rawString>R. Allen and D. Garlan, Ã¢ÂÂThe Wright architectural specification language,Ã¢ÂÂ CMU-CS-96-TB, School of Computer Science, Carnegie Mellon University, Pittsburgh, Sept. 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Luckham</author>
<author>J Vera</author>
</authors>
<title>Ã¢An event-based architecture definition language,Ã¢</title>
<date>1995</date>
<journal>IEEE Transactions on Software Engineering,</journal>
<volume>21</volume>
<pages>717--734</pages>
<contexts>
<context position="3863" citStr="[8]" startWordPosition="558" endWordPosition="558">on of the proposed solution can be downloaded from our website1. The proposed prototype is an integrated automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among the different solutions that can be found in literature [7], [8], [9], only few have practical relevance. Analyzability and tool support are key features of an ADL [10], [11]. Unfortunately the vast majority of ADLs offer very limited or no support for evaluating the alignment between intended (as defined in a model) and concrete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation</context>
</contexts>
<marker>[8]</marker>
<rawString>D. C. Luckham and J. Vera, Ã¢ÂÂAn event-based architecture definition language,Ã¢ÂÂ IEEE Transactions on Software Engineering, vol. 21, pp. 717Ã¢ÂÂ 734, Sept. 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P H Feiler</author>
<author>D P Gluch</author>
<author>J J Hudak</author>
</authors>
<title>Ã¢The architecture analysis &amp; design language (AADL): An introduction,Ã¢ tech. rep., DTIC Document,</title>
<date>2006</date>
<contexts>
<context position="3868" citStr="[9]" startWordPosition="559" endWordPosition="559"> the proposed solution can be downloaded from our website1. The proposed prototype is an integrated automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among the different solutions that can be found in literature [7], [8], [9], only few have practical relevance. Analyzability and tool support are key features of an ADL [10], [11]. Unfortunately the vast majority of ADLs offer very limited or no support for evaluating the alignment between intended (as defined in a model) and concrete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is t</context>
</contexts>
<marker>[9]</marker>
<rawString>P. H. Feiler, D. P. Gluch, and J. J. Hudak, Ã¢ÂÂThe architecture analysis &amp; design language (AADL): An introduction,Ã¢ÂÂ tech. rep., DTIC Document, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Medvidovic</author>
<author>E M Dashofy</author>
<author>R N Taylor</author>
</authors>
<title>Ã¢Moving architectural description from under the technology lamppost,Ã¢</title>
<date>2007</date>
<journal>Information and Software Technology,</journal>
<volume>49</volume>
<pages>12--31</pages>
<contexts>
<context position="3967" citStr="[10]" startWordPosition="575" endWordPosition="575">d automated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among the different solutions that can be found in literature [7], [8], [9], only few have practical relevance. Analyzability and tool support are key features of an ADL [10], [11]. Unfortunately the vast majority of ADLs offer very limited or no support for evaluating the alignment between intended (as defined in a model) and concrete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. T</context>
</contexts>
<marker>[10]</marker>
<rawString>N. Medvidovic, E. M. Dashofy, and R. N. Taylor, Ã¢ÂÂMoving architectural description from under the technology lamppost,Ã¢ÂÂ Information and Software Technology, vol. 49, no. 1, pp. 12Ã¢ÂÂ31, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Malavolta</author>
<author>P Lago</author>
<author>H Muccini</author>
<author>P Pelliccione</author>
<author>A Tang</author>
</authors>
<title>Ã¢What industry needs from architectural languages:</title>
<date>2013</date>
<journal>A survey,Ã¢ Software Engineering, IEEE Transactions on,</journal>
<volume>39</volume>
<pages>869--891</pages>
<contexts>
<context position="3973" citStr="[11]" startWordPosition="576" endWordPosition="576">mated architectural testing solution that accepts declaratively specified rules and checks for system compliance by interfacing with third-party tools. II. RELATED WORK Many approaches have been proposed for describing and checking architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among the different solutions that can be found in literature [7], [8], [9], only few have practical relevance. Analyzability and tool support are key features of an ADL [10], [11]. Unfortunately the vast majority of ADLs offer very limited or no support for evaluating the alignment between intended (as defined in a model) and concrete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. These t</context>
</contexts>
<marker>[11]</marker>
<rawString>I. Malavolta, P. Lago, H. Muccini, P. Pelliccione, and A. Tang, Ã¢ÂÂWhat industry needs from architectural languages: A survey,Ã¢ÂÂ Software Engineering, IEEE Transactions on, vol. 39, no. 6, pp. 869Ã¢ÂÂ891, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Booch</author>
<author>J Rumbaugh</author>
<author>I Jacobson</author>
</authors>
<title>The Unified Modeling Language User Guide.</title>
<date>2005</date>
<editor>second ed.,</editor>
<publisher>Addison Wesley,</publisher>
<location>Reading, Mass.:</location>
<contexts>
<context position="4203" citStr="[12]" startWordPosition="613" endWordPosition="613">g architectural properties and structures. ADLs are domain specific languages designed to capture the main concerns of one or more architectural views in a single uniform textual specification. Among the different solutions that can be found in literature [7], [8], [9], only few have practical relevance. Analyzability and tool support are key features of an ADL [10], [11]. Unfortunately the vast majority of ADLs offer very limited or no support for evaluating the alignment between intended (as defined in a model) and concrete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. These tools are typically specialized on a smaller, but therefore also more clearly defined, domain. Most of them are designed to evaluate module dependencies [13], [14] and performance (e.g., JMeter2, DynaTrace3, LoadRunner4). Meta-tool</context>
</contexts>
<marker>[12]</marker>
<rawString>G. Booch, J. Rumbaugh, and I. Jacobson, The Unified Modeling Language User Guide. Reading, Mass.: Addison Wesley, second ed., 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Knodel</author>
<author>D Muthig</author>
<author>M Naab</author>
<author>M Lindvall</author>
</authors>
<title>Ã¢Static evaluation of software architectures,Ã¢ in CSMRÃ¢06,</title>
<date>2006</date>
<pages>279--294</pages>
<publisher>IEEE Computer Society,</publisher>
<location>(Los Alamitos, CA, USA),</location>
<contexts>
<context position="4729" citStr="[13]" startWordPosition="693" endWordPosition="693">crete architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. These tools are typically specialized on a smaller, but therefore also more clearly defined, domain. Most of them are designed to evaluate module dependencies [13], [14] and performance (e.g., JMeter2, DynaTrace3, LoadRunner4). Meta-tools (e.g., Moose [15], IntensiVe [16]) can be used to build custom analyzers for verifying structural 1http://scg.unibe.ch/dicto/ 2http://jmeter.apache.org 3http://www.dynatrace.com 4http://www8.hp.com/us/en/software-solutions/loadrunner-load-testing/ properties. As explained in the introduction, these solutions come with various disadvantages that make their adoption costly and impractical. In order to offer a suitable, comprehensive and economical solution to conformance checking, we propose a new testing approach consis</context>
</contexts>
<marker>[13]</marker>
<rawString>J. Knodel, D. Muthig, M. Naab, and M. Lindvall, Ã¢ÂÂStatic evaluation of software architectures,Ã¢ÂÂ in CSMRÃ¢ÂÂ06, (Los Alamitos, CA, USA), pp. 279Ã¢ÂÂ294, IEEE Computer Society, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Bischofberger</author>
<author>J KuÃhl</author>
<author>S LoÃffler</author>
</authors>
<title>Ã¢Sotograph Ã¢ a pragmatic approach to source code architecture conformance checking,Ã¢</title>
<date>2004</date>
<booktitle>in Software Architecture,</booktitle>
<volume>3047</volume>
<pages>1--9</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="4735" citStr="[14]" startWordPosition="694" endWordPosition="694">architecture (as implemented in a system). Some ADLs (e.g., UML 2.0 [12]) could potentially be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. These tools are typically specialized on a smaller, but therefore also more clearly defined, domain. Most of them are designed to evaluate module dependencies [13], [14] and performance (e.g., JMeter2, DynaTrace3, LoadRunner4). Meta-tools (e.g., Moose [15], IntensiVe [16]) can be used to build custom analyzers for verifying structural 1http://scg.unibe.ch/dicto/ 2http://jmeter.apache.org 3http://www.dynatrace.com 4http://www8.hp.com/us/en/software-solutions/loadrunner-load-testing/ properties. As explained in the introduction, these solutions come with various disadvantages that make their adoption costly and impractical. In order to offer a suitable, comprehensive and economical solution to conformance checking, we propose a new testing approach consisting o</context>
</contexts>
<marker>[14]</marker>
<rawString>W. Bischofberger, J. KuÃÂhl, and S. LoÃÂffler, Ã¢ÂÂSotograph Ã¢ÂÂ a pragmatic approach to source code architecture conformance checking,Ã¢ÂÂ in Software Architecture, vol. 3047 of LNCS, pp. 1Ã¢ÂÂ9, Springer-Verlag, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ducasse</author>
<author>T GÃÂ±Ãrba</author>
<author>O Nierstrasz</author>
</authors>
<title>Ã¢Moose: an agile reengineering environment,Ã¢</title>
<date>2005</date>
<booktitle>in Proceedings of ESEC/FSE 2005,</booktitle>
<pages>99--102</pages>
<note>Tool demo.</note>
<contexts>
<context position="4822" citStr="[15]" startWordPosition="705" endWordPosition="705">ally be used to drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. These tools are typically specialized on a smaller, but therefore also more clearly defined, domain. Most of them are designed to evaluate module dependencies [13], [14] and performance (e.g., JMeter2, DynaTrace3, LoadRunner4). Meta-tools (e.g., Moose [15], IntensiVe [16]) can be used to build custom analyzers for verifying structural 1http://scg.unibe.ch/dicto/ 2http://jmeter.apache.org 3http://www.dynatrace.com 4http://www8.hp.com/us/en/software-solutions/loadrunner-load-testing/ properties. As explained in the introduction, these solutions come with various disadvantages that make their adoption costly and impractical. In order to offer a suitable, comprehensive and economical solution to conformance checking, we propose a new testing approach consisting of a business-readable rule specification DSL, called DictoÃ, and a tool coordination f</context>
</contexts>
<marker>[15]</marker>
<rawString>S. Ducasse, T. GÃÂ±ÃÂrba, and O. Nierstrasz, Ã¢ÂÂMoose: an agile reengineering environment,Ã¢ÂÂ in Proceedings of ESEC/FSE 2005, pp. 99Ã¢ÂÂ102, Sept. 2005. Tool demo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Mens</author>
<author>A Kellens</author>
</authors>
<title>Ã¢IntensiVE, a toolsuite for documenting and checking structural source-code regularities,Ã¢</title>
<date>2006</date>
<booktitle>in Software Maintenance and Reengineering,</booktitle>
<pages>10--248</pages>
<contexts>
<context position="4838" citStr="[16]" startWordPosition="707" endWordPosition="707">drive testing activities. Unfortunately, the absence of a shared and widely applicable set of tools and practices prevents the usage of such languages in a common industrial context. Somebody wanting to get around this limitation is therefore required to adopt one of the existing academic and commercial conformance testing tools. These tools are typically specialized on a smaller, but therefore also more clearly defined, domain. Most of them are designed to evaluate module dependencies [13], [14] and performance (e.g., JMeter2, DynaTrace3, LoadRunner4). Meta-tools (e.g., Moose [15], IntensiVe [16]) can be used to build custom analyzers for verifying structural 1http://scg.unibe.ch/dicto/ 2http://jmeter.apache.org 3http://www.dynatrace.com 4http://www8.hp.com/us/en/software-solutions/loadrunner-load-testing/ properties. As explained in the introduction, these solutions come with various disadvantages that make their adoption costly and impractical. In order to offer a suitable, comprehensive and economical solution to conformance checking, we propose a new testing approach consisting of a business-readable rule specification DSL, called DictoÃ, and a tool coordination framework, called</context>
</contexts>
<marker>[16]</marker>
<rawString>K. Mens and A. Kellens, Ã¢ÂÂIntensiVE, a toolsuite for documenting and checking structural source-code regularities,Ã¢ÂÂ in Software Maintenance and Reengineering, 2006. CSMR 2006. Proceedings of the 10th European Conference on, pp. 10 pp. Ã¢ÂÂ248, mar 2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>